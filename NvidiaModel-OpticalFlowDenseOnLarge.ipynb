{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Jonathan Mitchell\n",
    "### 03/31/17\n",
    "### Speed test challenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.gridspec as gridspec\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Data Acquisition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Create DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "* Create dataframe with image_path, time(seconds) and speed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "* In the video given, we have ~344 (5min 44s) seconds of video. \n",
    "* Our ground truth labels correspond to a video that is 12m 12s (~732seconds). \n",
    "* We only have a portion of that video. \n",
    "* It appears that our framerate <strong>~ 11.7552 fps </strong>. (8616 frames * (1 second / 13frames) = 344 seconds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8616"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./data/driving.csv')\n",
    "df.head(10)\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Plot Speeds vs Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEICAYAAABPgw/pAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nznRVbfzz4gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1b92c07518>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "times = np.asarray(df['time'], dtype = np.float32)\n",
    "speeds = np.asarray(df['speed'], dtype=np.float32)\n",
    "plt.plot(times, speeds, 'r-')\n",
    "plt.title('Speed vs Time')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_path</th>\n",
       "      <th>time</th>\n",
       "      <th>speed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8611</th>\n",
       "      <td>./data/IMG/732.6690168380737.jpg</td>\n",
       "      <td>732.669017</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8612</th>\n",
       "      <td>./data/IMG/732.78364777565.jpg</td>\n",
       "      <td>732.783648</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8613</th>\n",
       "      <td>./data/IMG/732.8334357738495.jpg</td>\n",
       "      <td>732.833436</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8614</th>\n",
       "      <td>./data/IMG/732.8638088703156.jpg</td>\n",
       "      <td>732.863809</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8615</th>\n",
       "      <td>./data/IMG/732.9520559310913.jpg</td>\n",
       "      <td>732.952056</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            image_path        time  speed\n",
       "8611  ./data/IMG/732.6690168380737.jpg  732.669017    0.0\n",
       "8612    ./data/IMG/732.78364777565.jpg  732.783648    0.0\n",
       "8613  ./data/IMG/732.8334357738495.jpg  732.833436    0.0\n",
       "8614  ./data/IMG/732.8638088703156.jpg  732.863809    0.0\n",
       "8615  ./data/IMG/732.9520559310913.jpg  732.952056    0.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Shuffle Pairs and Train Test Split\n",
    "* This function is a batch shuffler, \n",
    "* There is a 20% chance to add the row to validation data, other wise it will be train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def batch_shuffle(dframe):\n",
    "    \"\"\"\n",
    "    Randomly shuffle pairs of rows in the dataframe, separates train and validation data\n",
    "    generates a uniform random variable 0->9, gives 20% chance to append to valid data, otherwise train_data\n",
    "    return tuple (train_data, valid_data) dataframes\n",
    "    \"\"\"\n",
    "    train_data = pd.DataFrame()\n",
    "    valid_data = pd.DataFrame()\n",
    "    for i in range(len(dframe) - 1):\n",
    "        idx1 = np.random.randint(len(dframe) - 1)\n",
    "        idx2 = idx1 + 1\n",
    "        \n",
    "        row1 = dframe.iloc[[idx1]].reset_index()\n",
    "        row2 = dframe.iloc[[idx2]].reset_index()\n",
    "        \n",
    "        randInt = np.random.randint(9)\n",
    "        if 0 <= randInt <= 1:\n",
    "            valid_frames = [valid_data, row1, row2]\n",
    "            valid_data = pd.concat(valid_frames, axis = 0, join = 'outer', ignore_index=False)\n",
    "        if randInt >= 2:\n",
    "            train_frames = [train_data, row1, row2]\n",
    "            train_data = pd.concat(train_frames, axis = 0, join = 'outer', ignore_index=False)\n",
    "    return train_data, valid_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train_data, valid_data = batch_shuffle(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_data:  3720\n",
      "train_data:  13510\n"
     ]
    }
   ],
   "source": [
    "print('valid_data: ', len(valid_data))\n",
    "print('train_data: ', len(train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>image_path</th>\n",
       "      <th>time</th>\n",
       "      <th>speed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>307</td>\n",
       "      <td>./data/IMG/21.862053871154785.jpg</td>\n",
       "      <td>21.862054</td>\n",
       "      <td>3.526414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>308</td>\n",
       "      <td>./data/IMG/21.937291860580444.jpg</td>\n",
       "      <td>21.937292</td>\n",
       "      <td>3.525017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>44</td>\n",
       "      <td>./data/IMG/2.9507198333740234.jpg</td>\n",
       "      <td>2.950720</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>45</td>\n",
       "      <td>./data/IMG/2.9981889724731445.jpg</td>\n",
       "      <td>2.998189</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7251</td>\n",
       "      <td>./data/IMG/601.3976328372955.jpg</td>\n",
       "      <td>601.397633</td>\n",
       "      <td>25.619186</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                         image_path        time      speed\n",
       "0    307  ./data/IMG/21.862053871154785.jpg   21.862054   3.526414\n",
       "0    308  ./data/IMG/21.937291860580444.jpg   21.937292   3.525017\n",
       "0     44  ./data/IMG/2.9507198333740234.jpg    2.950720   0.000000\n",
       "0     45  ./data/IMG/2.9981889724731445.jpg    2.998189   0.000000\n",
       "0   7251   ./data/IMG/601.3976328372955.jpg  601.397633  25.619186"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def change_brightness(image, bright_factor):\n",
    "    \"\"\"\n",
    "    Augments the brightness of the image by multiplying the saturation by a uniform random variable\n",
    "    Input: image (RGB)\n",
    "    returns: image with brightness augmentation\n",
    "    \"\"\"\n",
    "    \n",
    "    hsv_image = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n",
    "    # perform brightness augmentation only on the second channel\n",
    "    hsv_image[:,:,2] = hsv_image[:,:,2] * bright_factor\n",
    "    \n",
    "    # change back to RGB\n",
    "    image_rgb = cv2.cvtColor(hsv_image, cv2.COLOR_HSV2RGB)\n",
    "    return image_rgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Optical Flow Dense\n",
    "* Two strategies\n",
    "* Strategy 1: get optical flow ang, magnitude, convert HSV to RGB and throw that image into the network\n",
    "* Strategy 2: get optical flow ang, magnitude, convert HSV to RGB then overlay ontop of original image and throw that into the network as RGB\n",
    "* Strategy 3: get optical flow parameters, ang, magnitude and expand dimensions of original image so you throw H x W x R x G x B x Ang x Magnitude into the network\n",
    "* Strategy 4: send in the flow differences as RGB (applied here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def opticalFlowDense(image_current, image_next):\n",
    "    \"\"\"\n",
    "    input: image_current, image_next (RGB images)\n",
    "    calculates optical flow magnitude and angle and places it into HSV image\n",
    "    * Set the saturation to the saturation value of image_next\n",
    "    * Set the hue to the angles returned from computing the flow params\n",
    "    * set the value to the magnitude returned from computing the flow params\n",
    "    * Convert from HSV to RGB and return RGB image with same size as original image\n",
    "    \"\"\"\n",
    "    gray_current = cv2.cvtColor(image_current, cv2.COLOR_RGB2GRAY)\n",
    "    gray_next = cv2.cvtColor(image_next, cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "    hsv = np.zeros((340, 550, 3))\n",
    "    # set saturation\n",
    "#     hsv[:,:,1] = cv2.cvtColor(image_next, cv2.COLOR_RGB2HSV)[:,:,1]\n",
    "    \n",
    "    # set saturation to 255\n",
    "    hsv[:,:,1] = 255\n",
    " \n",
    "    # Flow Parameters\n",
    "#     flow_mat = cv2.CV_32FC2\n",
    "    flow_mat = None\n",
    "    image_scale = 0.5\n",
    "    nb_images = 1\n",
    "    win_size = 15\n",
    "    nb_iterations = 2\n",
    "    deg_expansion = 5\n",
    "    STD = 1.3\n",
    "    extra = 0\n",
    "\n",
    "    # obtain dense optical flow paramters\n",
    "    flow = cv2.calcOpticalFlowFarneback(gray_current, gray_next,  \n",
    "                                        flow_mat, \n",
    "                                        image_scale, \n",
    "                                        nb_images, \n",
    "                                        win_size, \n",
    "                                        nb_iterations, \n",
    "                                        deg_expansion, \n",
    "                                        STD, \n",
    "                                        0)\n",
    "                                        \n",
    "        \n",
    "    # convert from cartesian to polar\n",
    "    mag, ang = cv2.cartToPolar(flow[..., 0], flow[..., 1])  \n",
    "        \n",
    "    # hue corresponds to direction\n",
    "    hsv[:,:,0] = ang * (180/ np.pi / 2)\n",
    "    \n",
    "    # value corresponds to magnitude\n",
    "    hsv[:,:,2] = cv2.normalize(mag,None,0,255,cv2.NORM_MINMAX)\n",
    "    \n",
    "    # convert HSV to float32's\n",
    "    hsv = np.asarray(hsv, dtype= np.float32)\n",
    "    rgb_flow = cv2.cvtColor(hsv,cv2.COLOR_HSV2RGB)\n",
    "\n",
    "    \n",
    "    return rgb_flow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Expand dims to add optical flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def preprocess_image(image):\n",
    "    \"\"\"\n",
    "    preprocesses the image\n",
    "    \n",
    "    input: image (480 (y), 640 (x), 3) RGB\n",
    "    output: image (shape is (220, 66, 3) as RGB)\n",
    "    \n",
    "    This stuff is performed on my validation data and my training data\n",
    "    Process: \n",
    "             1) Cropping out black spots\n",
    "             3) resize to (220, 66, 3) if not done so already from perspective transform\n",
    "    \"\"\"\n",
    "    # Crop out sky (top) (100px) and black right part (-90px)\n",
    "    image_cropped = image[100:440, :-90] # -> (340, 550, 3)\n",
    "        \n",
    "    return image_cropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def preprocess_image_valid_from_path(image_path, speed):\n",
    "    img = cv2.imread(image_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = preprocess_image(img)\n",
    "    return img, speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def preprocess_image_from_path(image_path, speed, bright_factor):\n",
    "    img = cv2.imread(image_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = change_brightness(img, bright_factor)    \n",
    "    img = preprocess_image(img)\n",
    "    return img, speed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Generators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Train Generator\n",
    "* This is used to yield train batches of rgb_flow and average speed. \n",
    "* We pick a random spot in the training dataset, between 1 and length - 1\n",
    "* determine the relationship between 3 frames\n",
    "* locate the current_frame and the next_frame\n",
    "* Take the rgb_flow and the average speed and build batches with that information\n",
    "* Then shuffle the batch and yield it, which will then be fed into the network\n",
    "* Generators allow me to not clog my memory stack so I can perform these operations on 16 (`BATCH` size) at a time. Note: We process 32 images each time the generator runs. If we run 8 epochs and 20480 samples per epoch we are processing 8 x 20480 x 32 = 5.2M images total."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def generate_training_data(data, batch_size = 32):\n",
    "    image_batch = np.zeros((batch_size, 66, 220, 3)) # nvidia input params\n",
    "    label_batch = np.zeros((batch_size))\n",
    "    while True:\n",
    "        for i in range(batch_size):\n",
    "            # generate a random index with a uniform random distribution from 1 to len - 1\n",
    "            idx = np.random.randint(1, len(data) - 1)\n",
    "            \n",
    "            \n",
    "            # Generate a random bright factor to apply to both images\n",
    "            bright_factor = 0.2 + np.random.uniform()\n",
    "            \n",
    "            row_now = data.iloc[[idx]].reset_index()\n",
    "            row_prev = data.iloc[[idx - 1]].reset_index()\n",
    "            row_next = data.iloc[[idx + 1]].reset_index()\n",
    "            \n",
    "            # Find the 3 respective times to determine frame order (current -> next)\n",
    "            \n",
    "            time_now = row_now['time'].values[0]\n",
    "            time_prev = row_prev['time'].values[0]\n",
    "            time_next = row_next['time'].values[0]\n",
    "            \n",
    "            if time_now - time_prev > 0 and 0.0000001 < time_now - time_prev < 0.58: # 0.578111 is highest diff i have seen\n",
    "                # in this case row_prev is x1 and row_now is x2\n",
    "                row1 = row_prev\n",
    "                row2 = row_now\n",
    "                \n",
    "            elif time_next - time_now > 0 and 0.0000001 < time_next - time_now < 0.58:\n",
    "                # in this case row_now is x1 and row_next is x2\n",
    "                row1 = row_now\n",
    "                row2 = row_next\n",
    "                \n",
    "                # Use this to find outliers\n",
    "            else:\n",
    "                print('time_now is not next or prev: ', time_now)\n",
    "                print('time_prev is :', time_prev)\n",
    "                print('time_next is: ', time_next)\n",
    "                \n",
    "                print('\\n diff: now  - prev \\t', time_now - time_prev)\n",
    "                print('\\n diff: next - now: \\t', time_next - time_now)\n",
    "            \n",
    "            \n",
    "            x1, y1 = preprocess_image_from_path(row1['image_path'].values[0],\n",
    "                                                row1['speed'].values[0],\n",
    "                                               bright_factor)\n",
    "            \n",
    "            # preprocess another image\n",
    "            x2, y2 = preprocess_image_from_path(row2['image_path'].values[0], \n",
    "                                                row2['speed'].values[0],\n",
    "                                               bright_factor)\n",
    "           \n",
    "            # compute optical flow send in images as RGB\n",
    "            rgb_diff = opticalFlowDense(x1, x2)\n",
    "            \n",
    "            rgb_diff_resized = cv2.resize(rgb_diff, (220, 66), interpolation = cv2.INTER_AREA)\n",
    "                        \n",
    "            # calculate mean speed\n",
    "            y = np.mean([y1, y2])\n",
    "            \n",
    "            image_batch[i] = rgb_diff_resized\n",
    "            label_batch[i] = y\n",
    "            \n",
    "        # Shuffle the pairs before they get fed into the network\n",
    "        yield shuffle(image_batch, label_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Validation Generator\n",
    "* This is used to yield validation rgb_flow and average speed. \n",
    "* We pick iterate through the validation data, determine the relationship between 3 frames, locate the current_frame and the next_frame. Take the rgb_flow and their average speed and feed that into the network\n",
    "* Reshape by adding an additional dimensions so the network perceives we are using a batch size of 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def generate_validation_data(data):\n",
    "    while True:\n",
    "        for idx in range(1, len(data) - 1): # start from the second row because we may try to grab it and need its prev to be in bounds\n",
    "            row_now = data.iloc[[idx]].reset_index()\n",
    "            row_prev = data.iloc[[idx - 1]].reset_index()\n",
    "            row_next = data.iloc[[idx + 1]].reset_index()\n",
    "            \n",
    "            # Find the 3 respective times to determine frame order (current -> next)\n",
    "            \n",
    "            time_now = row_now['time'].values[0]\n",
    "            time_prev = row_prev['time'].values[0]\n",
    "            time_next = row_next['time'].values[0]\n",
    "            \n",
    "            if time_now - time_prev > 0 and 0.0000001 < time_now - time_prev < 0.58:\n",
    "                # in this case row_prev is x1 and row_now is x2\n",
    "                row1 = row_prev\n",
    "                row2 = row_now\n",
    "                \n",
    "            elif time_next - time_now > 0 and 0.000001 < time_next - time_now < 0.58:\n",
    "                # in this case row_now is x1 and row_next is x2\n",
    "                row1 = row_now\n",
    "                row2 = row_next\n",
    "            \n",
    "            x1, y1 = preprocess_image_valid_from_path(row1['image_path'].values[0], row1['speed'].values[0])\n",
    "            x2, y2 = preprocess_image_valid_from_path(row2['image_path'].values[0], row2['speed'].values[0])\n",
    "            \n",
    "            img_diff = opticalFlowDense(x1, x2)\n",
    "            img_diff = cv2.resize(img_diff, (220, 66), interpolation = cv2.INTER_AREA)\n",
    "            img_diff = img_diff.reshape(1, img_diff.shape[0], img_diff.shape[1], img_diff.shape[2])\n",
    "            y = np.mean([y1, y2])\n",
    "            \n",
    "            speed = np.array([[y]])\n",
    "            yield img_diff, speed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Nvidia Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Architecture changed as a result of added dimensions\n",
    "* I added extra filters to try to capture more data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.core import Activation, Dropout, Flatten, Dense, Lambda\n",
    "from keras.layers import ELU\n",
    "from keras.optimizers import Adam\n",
    "import keras.backend.tensorflow_backend as KTF\n",
    "\n",
    "\n",
    "N_img_height = 66\n",
    "N_img_width = 220\n",
    "N_img_channels = 3\n",
    "def nvidia_model():\n",
    "    inputShape = (N_img_height, N_img_width, N_img_channels)\n",
    "\n",
    "    model = Sequential()\n",
    "    # normalization    \n",
    "    # perform custom normalization before lambda layer in network\n",
    "    model.add(Lambda(lambda x: x/ 127.5 - 1, input_shape = inputShape))\n",
    "\n",
    "    model.add(Convolution2D(24, (5, 5), \n",
    "                            strides=(2,2), \n",
    "                            padding = 'valid',\n",
    "                            kernel_initializer = 'he_normal',\n",
    "                            name = 'conv1'))\n",
    "    \n",
    "    \n",
    "    model.add(ELU())    \n",
    "    model.add(Convolution2D(36, (5, 5), \n",
    "                            strides=(2,2), \n",
    "                            padding = 'valid',\n",
    "                            kernel_initializer = 'he_normal',\n",
    "                            name = 'conv2'))\n",
    "    \n",
    "    model.add(ELU())    \n",
    "    model.add(Convolution2D(48, (5, 5), \n",
    "                            strides=(2,2), \n",
    "                            padding = 'valid',\n",
    "                            kernel_initializer = 'he_normal',\n",
    "                            name = 'conv3'))\n",
    "    model.add(ELU())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Convolution2D(64, (3, 3), \n",
    "                            strides = (1,1), \n",
    "                            padding = 'valid',\n",
    "                            kernel_initializer = 'he_normal',\n",
    "                            name = 'conv4'))\n",
    "    \n",
    "    model.add(ELU())              \n",
    "    model.add(Convolution2D(64, (3, 3), \n",
    "                            strides= (1,1), \n",
    "                            padding = 'valid',\n",
    "                            kernel_initializer = 'he_normal',\n",
    "                            name = 'conv5'))\n",
    "              \n",
    "              \n",
    "    model.add(Flatten(name = 'flatten'))\n",
    "    model.add(ELU())\n",
    "    model.add(Dense(100, kernel_initializer = 'he_normal', name = 'fc1'))\n",
    "    model.add(ELU())\n",
    "    model.add(Dense(50, kernel_initializer = 'he_normal', name = 'fc2'))\n",
    "    model.add(ELU())\n",
    "    model.add(Dense(10, kernel_initializer = 'he_normal', name = 'fc3'))\n",
    "    model.add(ELU())\n",
    "    \n",
    "    # do not put activation at the end because we want to exact output, not a class identifier\n",
    "    model.add(Dense(1, name = 'output', kernel_initializer = 'he_normal'))\n",
    "    \n",
    "    adam = Adam(lr=1e-4, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "    model.compile(optimizer = adam, loss = 'mse')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Define training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_size:  3720\n"
     ]
    }
   ],
   "source": [
    "val_size = len(valid_data.index)\n",
    "valid_generator = generate_validation_data(valid_data)\n",
    "BATCH = 16\n",
    "print('val_size: ', val_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Define model and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "filepath = 'model-weights-Vtest3.h5'\n",
    "earlyStopping = EarlyStopping(monitor='val_loss', \n",
    "                              patience=1, \n",
    "                              verbose=1, \n",
    "                              min_delta = 0.23,\n",
    "                              mode='min',)\n",
    "modelCheckpoint = ModelCheckpoint(filepath, \n",
    "                                  monitor = 'val_loss', \n",
    "                                  save_best_only = True, \n",
    "                                  mode = 'min', \n",
    "                                  verbose = 1,\n",
    "                                 save_weights_only = True)\n",
    "callbacks_list = [modelCheckpoint, earlyStopping]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "399/400 [============================>.] - ETA: 0s - loss: 110.0874  Epoch 00000: val_loss improved from inf to 74.98257, saving model to model-weights-Vtest3.h5\n",
      "400/400 [==============================] - 571s - loss: 109.8790 - val_loss: 74.9826\n",
      "Epoch 2/25\n",
      "399/400 [============================>.] - ETA: 0s - loss: 54.1003  Epoch 00001: val_loss improved from 74.98257 to 35.73771, saving model to model-weights-Vtest3.h5\n",
      "400/400 [==============================] - 560s - loss: 54.0369 - val_loss: 35.7377\n",
      "Epoch 3/25\n",
      "399/400 [============================>.] - ETA: 0s - loss: 36.4051  Epoch 00002: val_loss improved from 35.73771 to 33.47277, saving model to model-weights-Vtest3.h5\n",
      "400/400 [==============================] - 550s - loss: 36.3538 - val_loss: 33.4728\n",
      "Epoch 4/25\n",
      "399/400 [============================>.] - ETA: 0s - loss: 30.9962  Epoch 00003: val_loss improved from 33.47277 to 23.13717, saving model to model-weights-Vtest3.h5\n",
      "400/400 [==============================] - 553s - loss: 30.9515 - val_loss: 23.1372\n",
      "Epoch 5/25\n",
      "399/400 [============================>.] - ETA: 0s - loss: 24.5740  Epoch 00004: val_loss improved from 23.13717 to 19.88679, saving model to model-weights-Vtest3.h5\n",
      "400/400 [==============================] - 557s - loss: 24.5515 - val_loss: 19.8868\n",
      "Epoch 6/25\n",
      "399/400 [============================>.] - ETA: 0s - loss: 22.0520  Epoch 00005: val_loss improved from 19.88679 to 16.77905, saving model to model-weights-Vtest3.h5\n",
      "400/400 [==============================] - 559s - loss: 22.0896 - val_loss: 16.7790\n",
      "Epoch 7/25\n",
      "399/400 [============================>.] - ETA: 0s - loss: 19.6247  Epoch 00006: val_loss improved from 16.77905 to 15.33674, saving model to model-weights-Vtest3.h5\n",
      "400/400 [==============================] - 574s - loss: 19.6221 - val_loss: 15.3367\n",
      "Epoch 8/25\n",
      "399/400 [============================>.] - ETA: 0s - loss: 17.0934  Epoch 00007: val_loss improved from 15.33674 to 12.60576, saving model to model-weights-Vtest3.h5\n",
      "400/400 [==============================] - 558s - loss: 17.0764 - val_loss: 12.6058\n",
      "Epoch 9/25\n",
      "399/400 [============================>.] - ETA: 0s - loss: 15.8805  Epoch 00008: val_loss did not improve\n",
      "400/400 [==============================] - 552s - loss: 15.8705 - val_loss: 12.8202\n",
      "Epoch 10/25\n",
      "399/400 [============================>.] - ETA: 0s - loss: 14.3620  Epoch 00009: val_loss improved from 12.60576 to 11.78227, saving model to model-weights-Vtest3.h5\n",
      "400/400 [==============================] - 549s - loss: 14.3443 - val_loss: 11.7823\n",
      "Epoch 11/25\n",
      "399/400 [============================>.] - ETA: 0s - loss: 13.5617  Epoch 00010: val_loss improved from 11.78227 to 9.67027, saving model to model-weights-Vtest3.h5\n",
      "400/400 [==============================] - 542s - loss: 13.5535 - val_loss: 9.6703\n",
      "Epoch 12/25\n",
      "399/400 [============================>.] - ETA: 0s - loss: 12.0704  Epoch 00011: val_loss improved from 9.67027 to 9.54368, saving model to model-weights-Vtest3.h5\n",
      "400/400 [==============================] - 546s - loss: 12.0720 - val_loss: 9.5437\n",
      "Epoch 13/25\n",
      "399/400 [============================>.] - ETA: 0s - loss: 11.8630  Epoch 00012: val_loss improved from 9.54368 to 7.98998, saving model to model-weights-Vtest3.h5\n",
      "400/400 [==============================] - 578s - loss: 11.8525 - val_loss: 7.9900\n",
      "Epoch 14/25\n",
      "399/400 [============================>.] - ETA: 0s - loss: 10.3281  Epoch 00013: val_loss did not improve\n",
      "400/400 [==============================] - 590s - loss: 10.3690 - val_loss: 8.9256\n",
      "Epoch 15/25\n",
      "399/400 [============================>.] - ETA: 1s - loss: 9.1257   Epoch 00014: val_loss improved from 7.98998 to 7.06336, saving model to model-weights-Vtest3.h5\n",
      "400/400 [==============================] - 603s - loss: 9.1208 - val_loss: 7.0634\n",
      "Epoch 16/25\n",
      "399/400 [============================>.] - ETA: 0s - loss: 8.7144  Epoch 00015: val_loss did not improve\n",
      "400/400 [==============================] - 556s - loss: 8.7087 - val_loss: 7.6628\n",
      "Epoch 17/25\n",
      "399/400 [============================>.] - ETA: 0s - loss: 8.3564  Epoch 00016: val_loss improved from 7.06336 to 6.46731, saving model to model-weights-Vtest3.h5\n",
      "400/400 [==============================] - 561s - loss: 8.3418 - val_loss: 6.4673\n",
      "Epoch 18/25\n",
      "399/400 [============================>.] - ETA: 0s - loss: 7.6659   Epoch 00017: val_loss improved from 6.46731 to 6.20501, saving model to model-weights-Vtest3.h5\n",
      "400/400 [==============================] - 564s - loss: 7.6519 - val_loss: 6.2050\n",
      "Epoch 19/25\n",
      "399/400 [============================>.] - ETA: 0s - loss: 6.7187  Epoch 00018: val_loss improved from 6.20501 to 5.65061, saving model to model-weights-Vtest3.h5\n",
      "400/400 [==============================] - 563s - loss: 6.7056 - val_loss: 5.6506\n",
      "Epoch 20/25\n",
      "399/400 [============================>.] - ETA: 0s - loss: 6.3306  Epoch 00019: val_loss did not improve\n",
      "400/400 [==============================] - 562s - loss: 6.3477 - val_loss: 5.7962\n",
      "Epoch 21/25\n",
      "399/400 [============================>.] - ETA: 0s - loss: 6.7637  Epoch 00020: val_loss improved from 5.65061 to 5.11449, saving model to model-weights-Vtest3.h5\n",
      "400/400 [==============================] - 562s - loss: 6.7701 - val_loss: 5.1145\n",
      "Epoch 22/25\n",
      "399/400 [============================>.] - ETA: 0s - loss: 6.1138  Epoch 00021: val_loss did not improve\n",
      "400/400 [==============================] - 561s - loss: 6.1108 - val_loss: 5.4395\n",
      "Epoch 23/25\n",
      "399/400 [============================>.] - ETA: 1s - loss: 5.6622  Epoch 00022: val_loss improved from 5.11449 to 4.87868, saving model to model-weights-Vtest3.h5\n",
      "400/400 [==============================] - 613s - loss: 5.6550 - val_loss: 4.8787\n",
      "Epoch 24/25\n",
      "399/400 [============================>.] - ETA: 0s - loss: 5.5984  Epoch 00023: val_loss did not improve\n",
      "400/400 [==============================] - 548s - loss: 5.6094 - val_loss: 5.4155\n",
      "Epoch 25/25\n",
      "399/400 [============================>.] - ETA: 0s - loss: 4.8124  Epoch 00024: val_loss did not improve\n",
      "400/400 [==============================] - 546s - loss: 4.8089 - val_loss: 5.3988\n",
      "Epoch 00024: early stopping\n",
      "<keras.callbacks.History object at 0x7fa1900e7470>\n"
     ]
    }
   ],
   "source": [
    "model = nvidia_model()\n",
    "train_size = len(train_data.index)\n",
    "train_generator = generate_training_data(train_data, BATCH)\n",
    "history = model.fit_generator(\n",
    "        train_generator, \n",
    "        steps_per_epoch = 400, \n",
    "        epochs = 25,\n",
    "    callbacks = callbacks_list,\n",
    "        verbose = 1,\n",
    "        validation_data = valid_generator,\n",
    "        validation_steps = val_size)\n",
    "\n",
    "print(history)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['val_loss', 'loss'])\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa157ee22b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(history.history.keys())\n",
    "\n",
    "### plot the training and validation loss for each epoch\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model-v2test mean squared error loss 15 epochs')\n",
    "plt.ylabel('mean squared error loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['training set', 'validation set'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Optical Flow Approach MSE: ~5.5 for 15 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model_v2_loss = mpimg.imread('./model-vtest-2-loss.png')\n",
    "plt.imshow(model_v2_loss)\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Analysis\n",
    "* When passing the angle, and magnitude received from the optical flow calculation to the network my MSE is:\n",
    "* Method 1: Passing optical flow as RGB image only instead of the original image as well\n",
    "* In the end I went with the 7 epoch trained model because I had a good feeling it would be able to generalize well and was not overfit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "When passing in just the image, the MSE doesn't converge as well"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Train data preprocessing view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# random selection\n",
    "data = train_data\n",
    "random_images = []\n",
    "for i in range(20):\n",
    "    idx = np.random.randint(len(data))\n",
    "    bright_factor = 0.2 + np.random.uniform()\n",
    "    row = data.iloc[[idx]].reset_index()\n",
    "    x, y = preprocess_image_from_path(row['image_path'].values[0], row['speed'].values[0], bright_factor)\n",
    "    random_images.append((x, y))\n",
    "    \n",
    "plt.figure(figsize=(16, 10))\n",
    "gs1 = gridspec.GridSpec(4, 5)\n",
    "gs1.update(wspace = 0.01, hspace = 0.01)\n",
    "for idx, image in enumerate(random_images):\n",
    "    angle = 'speed: ' + str(image[1]) \n",
    "    ax1 = plt.subplot(gs1[idx])\n",
    "    ax1.axis('off')\n",
    "    plt.title(angle)\n",
    "    plt.imshow(image[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Validation data preprocessing view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# random selection\n",
    "data = train_data\n",
    "random_images = []\n",
    "for i in range(20):\n",
    "    idx = np.random.randint(len(data))\n",
    "    row = data.iloc[[idx]].reset_index()\n",
    "    x, y = preprocess_image_valid_from_path(row['image_path'].values[0], row['speed'].values[0])\n",
    "    random_images.append((x, y))\n",
    "    \n",
    "plt.figure(figsize=(16, 10))\n",
    "gs1 = gridspec.GridSpec(4, 5)\n",
    "gs1.update(wspace = 0.01, hspace = 0.01)\n",
    "for idx, image in enumerate(random_images):\n",
    "    angle = 'speed: ' + str(image[1]) \n",
    "    ax1 = plt.subplot(gs1[idx])\n",
    "    ax1.axis('off')\n",
    "    plt.title(angle)\n",
    "    plt.imshow(image[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### IDEAS: \n",
    "* Run forwards (img1 - img2) mean(speed)\n",
    "* Run backwards (img2 - img1) mean(speed)\n",
    "* Compute speed differential then apply prediction as: current_speed += speed_difference\n",
    "* speed_difference = xW + b\n",
    "* Optical Flow\n",
    "* Batch shuffler\n",
    "* Apply perspective transform\n",
    "* Sobely gradient \n",
    "* Gaussian blur"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Design considerations\n",
    "* Originally I generated a new brightness factor for each image, but that created some disturbances when I wanted to take the difference between both images so instead I used the same brightness augmentation for the current_frame and the next_frame. It works both ways though, it may have been better to make a random brightness augmentation because at one instant if our frame is under clear lighting, and the next frame has a shadow, we would not know how to consider that pixel difference. \n",
    "* I used a generator and yielded batches of my results, I did this so I didn't clog my memory stack while training my model\n",
    "* I took the input data and pushed the video images into a separate file and created a driving.csv file so I could use a pandas dataframe to read in each image path and only read in the image once I am in the generator. I could have just used moviepy and created a VideoFileClip and run all processing steps on each image, but I wouldn't have the same amount of control when testing out my preprocessing and data augmentation pipelines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "* Evaluate on subset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Upload 14 epoch model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model = nvidia_model()\n",
    "model.load_weights('model-weights-Vtest2.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Overlay prediction onto images and save to new directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def opticalFlowOverlay(image_current, image_next):\n",
    "    \"\"\"\n",
    "    input: image_current, image_next (RGB images)\n",
    "    output: mask\n",
    "    \"\"\"\n",
    "    feature_params = dict( maxCorners = 500,\n",
    "                       qualityLevel = 0.1,\n",
    "                       minDistance = 7,\n",
    "                       blockSize = 5 )\n",
    "    lk_params = dict( winSize  = (15, 15),\n",
    "                  maxLevel = 2,\n",
    "                  criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03))\n",
    "    \n",
    "    image_current_saved = np.copy(image_current)\n",
    "    image_next_saved = np.copy(image_next)\n",
    "    \n",
    "    image_current = cv2.cvtColor(image_current, cv2.COLOR_RGB2GRAY)\n",
    "    image_next = cv2.cvtColor(image_next, cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "    p0 = cv2.goodFeaturesToTrack(image_current, mask = None, **feature_params)\n",
    "\n",
    "    p1, st, err = cv2.calcOpticalFlowPyrLK(image_current, image_next, p0, None, **lk_params)\n",
    "\n",
    "\n",
    "    color = np.random.randint(0, 255, (100, 3))\n",
    "\n",
    "    mask = np.zeros_like(image_current)\n",
    "\n",
    "    # Select good points\n",
    "    good_new = p1[st == 1]\n",
    "    good_old = p0[st == 1]\n",
    "    for i, (new, old) in enumerate(zip(good_new, good_old)):\n",
    "        a, b = new.ravel() # flatten\n",
    "        c, d = old.ravel()\n",
    "        mask = cv2.arrowedLine(mask, (a,b), (c, d), color[i].tolist(), 1, 8)\n",
    "        \n",
    "        image_next = cv2.circle(image_next_saved, (a, b), 1, color[i].tolist(), -1)\n",
    "        image_next_fg = cv2.bitwise_and(image_next, image_next, mask = mask)\n",
    "        \n",
    "    dst = cv2.add(image_next, image_next_fg)\n",
    "    return dst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "mkdir ./data/predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "# given an input image\n",
    "\n",
    "data = pd.read_csv('./data/driving.csv')                    \n",
    "for idx in range(1, len(data.index) - 1):\n",
    "    row_now = data.iloc[[idx]].reset_index()\n",
    "    row_prev = data.iloc[[idx - 1]].reset_index()\n",
    "    row_next = data.iloc[[idx + 1]].reset_index()\n",
    "\n",
    "    # Find the 3 respective times to determine frame order (current -> next)\n",
    "\n",
    "    time_now = row_now['time'].values[0]\n",
    "    time_prev = row_prev['time'].values[0]\n",
    "    time_next = row_next['time'].values[0]\n",
    "\n",
    "    if time_now - time_prev > 0 and 0.0000001 < time_now - time_prev < 0.58: # 0.578111 is highest diff i have seen\n",
    "        # in this case row_prev is x1 and row_now is x2\n",
    "        row1 = row_prev\n",
    "        row2 = row_now\n",
    "\n",
    "    elif time_next - time_now > 0 and 0.0000001 < time_next - time_now < 0.58:\n",
    "        # in this case row_now is x1 and row_next is x2\n",
    "        row1 = row_now\n",
    "        row2 = row_next\n",
    "\n",
    "    x1, y1 = preprocess_image_valid_from_path(row1['image_path'].values[0], row1['speed'].values[0])\n",
    "    x2, y2 = preprocess_image_valid_from_path(row2['image_path'].values[0], row2['speed'].values[0])\n",
    "    img_diff = x1 - x2\n",
    "                                   \n",
    "    # reshape image difference to feed into model.predict\n",
    "    img_diff = opticalFlowDense(x1, x2)\n",
    "    img_diff_reshaped = img_diff.reshape(1, img_diff.shape[0], img_diff.shape[1], img_diff.shape[2])\n",
    "        \n",
    "    # grab the mean speed y to check our model against\n",
    "    y = np.mean([y1, y2])\n",
    "                                   \n",
    "    # note: y2 is the actual speed of the frame x2 which we will use for accurate prediction, even though\n",
    "    # our model is based on x1 and x2\n",
    "                                   \n",
    "    # TODO: retrain model to evaluate y2 instead of mean(y1, y2) and check differences\n",
    "                                   \n",
    "    prediction = model.predict(img_diff_reshaped)\n",
    "    error = abs(prediction - y2)\n",
    "    truth = y2\n",
    "                                       \n",
    "    predict_path = os.path.join('./data/predict/', str(idx) + '.jpg')\n",
    "                                   \n",
    "    # overwrite the prediction of y2 onto image x2\n",
    "    # save overwritten image x2 to new directory ./data/predict\n",
    "\n",
    "                                   \n",
    "    # Make a copy \n",
    "    dst = np.copy(x2)\n",
    "    \n",
    "    dst = opticalFlowOverlay(x1, x2) # This is a sparse optical flow overlay    \n",
    "    \n",
    "    # to write new image via openCV\n",
    "    offset = 10\n",
    "    FONT_SIZE = 0.3\n",
    "    THICKNESS = 1\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    cv2.putText(dst,'pred: ' + str(prediction[0][0])[:5],(5,offset), font, FONT_SIZE,(0,0,0), THICKNESS,cv2.LINE_AA)\n",
    "    cv2.putText(dst,'truth: ' + str(y2)[:5],(5,offset * 2), font, FONT_SIZE,(0,20,255), THICKNESS,cv2.LINE_AA)\n",
    "    cv2.putText(dst, 'error: ' + str(error[0][0])[:5], (5, offset*3),font, FONT_SIZE, (255, 0, 0), THICKNESS, cv2.LINE_AA)\n",
    "    \n",
    "    # convert back to BGR for writing\n",
    "    dst = cv2.cvtColor(dst, cv2.COLOR_RGB2BGR)\n",
    "    cv2.imwrite(predict_path, dst)\n",
    "    \n",
    "print('done!')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Create video from sequence of images\n",
    "* These videos are from dense optical flow method, where I compute the dense optical flow and convert that to an rgb image and pass it into the network. There is a video for the 30 epoch non-optical flow model which is on youtube [here](http://www.youtube.com/embed/WofBjhlaWqQ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from moviepy.editor import VideoFileClip\n",
    "from moviepy.editor import ImageSequenceClip\n",
    "import glob\n",
    "import os\n",
    "\n",
    "images = ['./data/predict/' + str(i+1) + '.jpg' for i in range(0, 8614)]\n",
    "clip = ImageSequenceClip(images, fps=11.7552)\n",
    "clip.write_videofile(\"movie_vtest2.mp4\", fps=11.7552)\n",
    "print('done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# rm -rf ./data/predict/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## movie_vtest1.mp4 (10 epoch MSE ~ 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format('movie_vtest.mp4'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "This model is clearly overfit as you can see that the prediction is trying to predict high speeds during the freeway exit, but the ground truth happens to be set to a low speed. Here you can see that it attempts to predict the high speed but then it falls back down towards the ground truth speed. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### movie vtest2 Video: Optical Flow Method 2, 15 epochs MSE: ~5.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format('movie_vtest2.mp4'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### M3 Video Optical Flow Method, 16 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format('movie_small_optical_dense_M3.mp4'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "This one may have overfit just a bit, bit it looks really nice!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### For fun: Sparse Optical Flow Overlay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format('movie_small_optical_dense_M3_sparseoverlay.mp4'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Reflections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "* When I extract the image frames from the video file, I do so at a constant rate, splitting the 8616 frames evenly. In the ground truth dataset it is shown that images are not captured with a uniform sampling rate, so in each image, there is a slight error in the actual speed for that image. Meaning It will be unlikely that I can detect very rapid changes in speed.\n",
    "* I should have extracted the images using `ffmpeg -ss 0.5 -i inputfile.mp4 -t 1 -s 480x300 -f image2 imagefile.jpg`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Other Approaches\n",
    "* I notices this article: (http://nicolovaligi.com/car-speed-estimation-windshield-camera.html#Giachetti1999) and this code: (https://gist.github.com/nicolov/d010233ea8d35887c6ab47cca97d396f) that uses Optical Flow to for Car Speed estimation using a single windshield camera. I copied the code, modified some fields so it worked with my dataset and ran it to see what happens.\n",
    "* An interesting thing to note is that in this code he is using ground truth data to calibrate the `hf` factor. Still, once the car goes on the freeway and deals with speeds > 30mph it fails completely. \n",
    "I ran the code with my dataset, which you can see in <strong>OpticalFlow.ipynb </strong>, and here is the result I got.\n",
    "* When I ran this code, I cropped out a ton of the image, meaning I lost a bunch of data. There are points when driving that the background and scenery can help define changes in velocity. Such as the difference in a trees position from one frame to the next, for this reason I went with the CNN approach.\n",
    "* Next steps: My next step is to compute the optical flow for each (current_image, next_frame) and feed that into my network as well. This way I can have the best of both worlds. Stay tuned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Future considerations\n",
    "* If I had more time I would finish my DeepVO implementation [DeepVO](https://arxiv.org/pdf/1611.06069.pdf), which I started to write but did not finish. You can see DeepVO in <strong>DeepVO.ipynb</strong>\n",
    "* I would also try to implement [DeepFlow](http://www.cv-foundation.org/openaccess/content_iccv_2013/papers/Weinzaepfel_DeepFlow_Large_Displacement_2013_ICCV_paper.pdf) which claims to have great performance. \n",
    "* I would also consider trying [FlowNet](https://arxiv.org/pdf/1504.06852.pdf) and I would use this as a [guide] (https://github.com/ClementPinard/FlowNetPytorch)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
