{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Jonathan Mitchell\n",
    "### 03/31/17\n",
    "### Speed test challenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.gridspec as gridspec\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Data Acquisition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Create DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "* Create dataframe with image_path, time(seconds) and speed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "* In the video given, we have ~344 (5min 44s) seconds of video. \n",
    "* Our ground truth labels correspond to a video that is 12m 12s (~732seconds). \n",
    "* We only have a portion of that video. \n",
    "* It appears that our framerate <strong>~ 11.7552 fps </strong>. (8616 frames * (1 second / 13frames) = 344 seconds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8616"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./data/driving.csv')\n",
    "df.head(10)\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Plot Speeds vs Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEICAYAAABPgw/pAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nznRVbfzz4gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f37bc615908>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "times = np.asarray(df['time'], dtype = np.float32)\n",
    "speeds = np.asarray(df['speed'], dtype=np.float32)\n",
    "plt.plot(times, speeds, 'r-')\n",
    "plt.title('Speed vs Time')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_path</th>\n",
       "      <th>time</th>\n",
       "      <th>speed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8611</th>\n",
       "      <td>./data/IMG/732.6690168380737.jpg</td>\n",
       "      <td>732.669017</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8612</th>\n",
       "      <td>./data/IMG/732.78364777565.jpg</td>\n",
       "      <td>732.783648</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8613</th>\n",
       "      <td>./data/IMG/732.8334357738495.jpg</td>\n",
       "      <td>732.833436</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8614</th>\n",
       "      <td>./data/IMG/732.8638088703156.jpg</td>\n",
       "      <td>732.863809</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8615</th>\n",
       "      <td>./data/IMG/732.9520559310913.jpg</td>\n",
       "      <td>732.952056</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            image_path        time  speed\n",
       "8611  ./data/IMG/732.6690168380737.jpg  732.669017    0.0\n",
       "8612    ./data/IMG/732.78364777565.jpg  732.783648    0.0\n",
       "8613  ./data/IMG/732.8334357738495.jpg  732.833436    0.0\n",
       "8614  ./data/IMG/732.8638088703156.jpg  732.863809    0.0\n",
       "8615  ./data/IMG/732.9520559310913.jpg  732.952056    0.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Shuffle Pairs and Train Test Split\n",
    "* This function is a batch shuffler, \n",
    "* There is a 20% chance to add the row to validation data, other wise it will be train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def batch_shuffle(dframe):\n",
    "    \"\"\"\n",
    "    Randomly shuffle pairs of rows in the dataframe, separates train and validation data\n",
    "    generates a uniform random variable 0->9, gives 20% chance to append to valid data, otherwise train_data\n",
    "    return tuple (train_data, valid_data) dataframes\n",
    "    \"\"\"\n",
    "    train_data = pd.DataFrame()\n",
    "    valid_data = pd.DataFrame()\n",
    "    for i in range(len(dframe) - 1):\n",
    "        idx1 = np.random.randint(len(dframe) - 1)\n",
    "        idx2 = idx1 + 1\n",
    "        \n",
    "        row1 = dframe.iloc[[idx1]].reset_index()\n",
    "        row2 = dframe.iloc[[idx2]].reset_index()\n",
    "        \n",
    "        randInt = np.random.randint(9)\n",
    "        if 0 <= randInt <= 1:\n",
    "            valid_frames = [valid_data, row1, row2]\n",
    "            valid_data = pd.concat(valid_frames, axis = 0, join = 'outer', ignore_index=False)\n",
    "        if randInt >= 2:\n",
    "            train_frames = [train_data, row1, row2]\n",
    "            train_data = pd.concat(train_frames, axis = 0, join = 'outer', ignore_index=False)\n",
    "    return train_data, valid_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train_data, valid_data = batch_shuffle(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_data:  3754\n",
      "train_data:  13476\n"
     ]
    }
   ],
   "source": [
    "print('valid_data: ', len(valid_data))\n",
    "print('train_data: ', len(train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>image_path</th>\n",
       "      <th>time</th>\n",
       "      <th>speed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4709</td>\n",
       "      <td>./data/IMG/366.7089958190918.jpg</td>\n",
       "      <td>366.708996</td>\n",
       "      <td>27.816654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4710</td>\n",
       "      <td>./data/IMG/366.8006069660187.jpg</td>\n",
       "      <td>366.800607</td>\n",
       "      <td>27.804988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5877</td>\n",
       "      <td>./data/IMG/473.7397708892822.jpg</td>\n",
       "      <td>473.739771</td>\n",
       "      <td>19.989897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5878</td>\n",
       "      <td>./data/IMG/473.82461380958557.jpg</td>\n",
       "      <td>473.824614</td>\n",
       "      <td>19.949778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>446</td>\n",
       "      <td>./data/IMG/31.85455298423767.jpg</td>\n",
       "      <td>31.854553</td>\n",
       "      <td>7.288291</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                         image_path        time      speed\n",
       "0   4709   ./data/IMG/366.7089958190918.jpg  366.708996  27.816654\n",
       "0   4710   ./data/IMG/366.8006069660187.jpg  366.800607  27.804988\n",
       "0   5877   ./data/IMG/473.7397708892822.jpg  473.739771  19.989897\n",
       "0   5878  ./data/IMG/473.82461380958557.jpg  473.824614  19.949778\n",
       "0    446   ./data/IMG/31.85455298423767.jpg   31.854553   7.288291"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def change_brightness(image, bright_factor):\n",
    "    \"\"\"\n",
    "    Augments the brightness of the image by multiplying the saturation by a uniform random variable\n",
    "    Input: image (RGB)\n",
    "    returns: image with brightness augmentation\n",
    "    \"\"\"\n",
    "    \n",
    "    hsv_image = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n",
    "    # perform brightness augmentation only on the second channel\n",
    "    hsv_image[:,:,2] = hsv_image[:,:,2] * bright_factor\n",
    "    \n",
    "    # change back to RGB\n",
    "    image_rgb = cv2.cvtColor(hsv_image, cv2.COLOR_HSV2RGB)\n",
    "    return image_rgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Optical Flow Dense\n",
    "* Two strategies\n",
    "* Strategy 1: get optical flow ang, magnitude, convert HSV to RGB and throw that image into the network\n",
    "* Strategy 2: get optical flow ang, magnitude, convert HSV to RGB then overlay ontop of original image and throw that into the network as RGB\n",
    "* Strategy 3: get optical flow parameters, ang, magnitude and expand dimensions of original image so you throw H x W x R x G x B x Ang x Magnitude into the network\n",
    "* Strategy 4: send in the flow differences as RGB (applied here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def opticalFlowDense(image_current, image_next):\n",
    "    \"\"\"\n",
    "    input: image_current, image_next (RGB images)\n",
    "    calculates optical flow magnitude and angle and places it into HSV image\n",
    "    * Set the saturation to the saturation value of image_next\n",
    "    * Set the hue to the angles returned from computing the flow params\n",
    "    * set the value to the magnitude returned from computing the flow params\n",
    "    * Convert from HSV to RGB and return RGB image with same size as original image\n",
    "    \"\"\"\n",
    "    gray_current = cv2.cvtColor(image_current, cv2.COLOR_RGB2GRAY)\n",
    "    gray_next = cv2.cvtColor(image_next, cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "    \n",
    "    hsv = np.zeros((66, 220, 3))\n",
    "    # set saturation\n",
    "    hsv[:,:,1] = cv2.cvtColor(image_next, cv2.COLOR_RGB2HSV)[:,:,1]\n",
    " \n",
    "    # Flow Parameters\n",
    "#     flow_mat = cv2.CV_32FC2\n",
    "    flow_mat = None\n",
    "    image_scale = 0.5\n",
    "    nb_images = 1\n",
    "    win_size = 15\n",
    "    nb_iterations = 2\n",
    "    deg_expansion = 5\n",
    "    STD = 1.3\n",
    "    extra = 0\n",
    "\n",
    "    # obtain dense optical flow paramters\n",
    "    flow = cv2.calcOpticalFlowFarneback(gray_current, gray_next,  \n",
    "                                        flow_mat, \n",
    "                                        image_scale, \n",
    "                                        nb_images, \n",
    "                                        win_size, \n",
    "                                        nb_iterations, \n",
    "                                        deg_expansion, \n",
    "                                        STD, \n",
    "                                        0)\n",
    "                                        \n",
    "        \n",
    "    # convert from cartesian to polar\n",
    "    mag, ang = cv2.cartToPolar(flow[..., 0], flow[..., 1])  \n",
    "        \n",
    "    # hue corresponds to direction\n",
    "    hsv[:,:,0] = ang * (180/ np.pi / 2)\n",
    "    \n",
    "    # value corresponds to magnitude\n",
    "    hsv[:,:,2] = cv2.normalize(mag,None,0,255,cv2.NORM_MINMAX)\n",
    "    \n",
    "    # convert HSV to float32's\n",
    "    hsv = np.asarray(hsv, dtype= np.float32)\n",
    "    rgb_flow = cv2.cvtColor(hsv,cv2.COLOR_HSV2RGB)\n",
    "\n",
    "    \n",
    "    return rgb_flow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Expand dims to add optical flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def preprocess_image(image):\n",
    "    \"\"\"\n",
    "    preprocesses the image\n",
    "    \n",
    "    input: image (480 (y), 640 (x), 3) RGB\n",
    "    output: image (shape is (220, 66, 3) as RGB)\n",
    "    \n",
    "    This stuff is performed on my validation data and my training data\n",
    "    Process: \n",
    "             1) Cropping out black spots\n",
    "             3) resize to (220, 66, 3) if not done so already from perspective transform\n",
    "    \"\"\"\n",
    "    # Crop out sky (top) (100px) and black right part (-90px)\n",
    "    image_cropped = image[100:440, :-90] # -> (380, 550, 3)\n",
    "    \n",
    "    image = cv2.resize(image_cropped, (220, 66), interpolation = cv2.INTER_AREA)\n",
    "    \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def preprocess_image_valid_from_path(image_path, speed):\n",
    "    img = cv2.imread(image_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = preprocess_image(img)\n",
    "    return img, speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def preprocess_image_from_path(image_path, speed, bright_factor):\n",
    "    img = cv2.imread(image_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = change_brightness(img, bright_factor)    \n",
    "    img = preprocess_image(img)\n",
    "    return img, speed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Generators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Train Generator\n",
    "* This is used to yield train batches of rgb_flow and average speed. \n",
    "* We pick a random spot in the training dataset, between 1 and length - 1\n",
    "* determine the relationship between 3 frames\n",
    "* locate the current_frame and the next_frame\n",
    "* Take the rgb_flow and the average speed and build batches with that information\n",
    "* Then shuffle the batch and yield it, which will then be fed into the network\n",
    "* Generators allow me to not clog my memory stack so I can perform these operations on 16 (`BATCH` size) at a time. Note: We process 32 images each time the generator runs. If we run 8 epochs and 20480 samples per epoch we are processing 8 x 20480 x 32 = 5.2M images total."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def generate_training_data(data, batch_size = 32):\n",
    "    image_batch = np.zeros((batch_size, 66, 220, 3)) # nvidia input params\n",
    "    label_batch = np.zeros((batch_size))\n",
    "    while True:\n",
    "        for i in range(batch_size):\n",
    "            # generate a random index with a uniform random distribution from 1 to len - 1\n",
    "            idx = np.random.randint(1, len(data) - 1)\n",
    "            \n",
    "            \n",
    "            # Generate a random bright factor to apply to both images\n",
    "            bright_factor = 0.2 + np.random.uniform()\n",
    "            \n",
    "            row_now = data.iloc[[idx]].reset_index()\n",
    "            row_prev = data.iloc[[idx - 1]].reset_index()\n",
    "            row_next = data.iloc[[idx + 1]].reset_index()\n",
    "            \n",
    "            # Find the 3 respective times to determine frame order (current -> next)\n",
    "            \n",
    "            time_now = row_now['time'].values[0]\n",
    "            time_prev = row_prev['time'].values[0]\n",
    "            time_next = row_next['time'].values[0]\n",
    "            \n",
    "            if time_now - time_prev > 0 and 0.0000001 < time_now - time_prev < 0.58: # 0.578111 is highest diff i have seen\n",
    "                # in this case row_prev is x1 and row_now is x2\n",
    "                row1 = row_prev\n",
    "                row2 = row_now\n",
    "                \n",
    "            elif time_next - time_now > 0 and 0.0000001 < time_next - time_now < 0.58:\n",
    "                # in this case row_now is x1 and row_next is x2\n",
    "                row1 = row_now\n",
    "                row2 = row_next\n",
    "                \n",
    "                # Use this to find outliers\n",
    "            else:\n",
    "                print('time_now is not next or prev: ', time_now)\n",
    "                print('time_prev is :', time_prev)\n",
    "                print('time_next is: ', time_next)\n",
    "                \n",
    "                print('\\n diff: now  - prev \\t', time_now - time_prev)\n",
    "                print('\\n diff: next - now: \\t', time_next - time_now)\n",
    "            \n",
    "            \n",
    "            x1, y1 = preprocess_image_from_path(row1['image_path'].values[0],\n",
    "                                                row1['speed'].values[0],\n",
    "                                               bright_factor)\n",
    "            \n",
    "            # preprocess another image\n",
    "            x2, y2 = preprocess_image_from_path(row2['image_path'].values[0], \n",
    "                                                row2['speed'].values[0],\n",
    "                                               bright_factor)\n",
    "           \n",
    "            # compute optical flow send in images as RGB\n",
    "            rgb_diff = opticalFlowDense(x1, x2)\n",
    "                        \n",
    "            # calculate mean speed\n",
    "            y = np.mean([y1, y2])\n",
    "            \n",
    "            image_batch[i] = rgb_diff\n",
    "            label_batch[i] = y\n",
    "            \n",
    "        # Shuffle the pairs before they get fed into the network\n",
    "        yield shuffle(image_batch, label_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Validation Generator\n",
    "* This is used to yield validation rgb_flow and average speed. \n",
    "* We pick iterate through the validation data, determine the relationship between 3 frames, locate the current_frame and the next_frame. Take the rgb_flow and their average speed and feed that into the network\n",
    "* Reshape by adding an additional dimensions so the network perceives we are using a batch size of 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def generate_validation_data(data):\n",
    "    while True:\n",
    "        for idx in range(1, len(data) - 1): # start from the second row because we may try to grab it and need its prev to be in bounds\n",
    "            row_now = data.iloc[[idx]].reset_index()\n",
    "            row_prev = data.iloc[[idx - 1]].reset_index()\n",
    "            row_next = data.iloc[[idx + 1]].reset_index()\n",
    "            \n",
    "            # Find the 3 respective times to determine frame order (current -> next)\n",
    "            \n",
    "            time_now = row_now['time'].values[0]\n",
    "            time_prev = row_prev['time'].values[0]\n",
    "            time_next = row_next['time'].values[0]\n",
    "            \n",
    "            if time_now - time_prev > 0 and 0.0000001 < time_now - time_prev < 0.58:\n",
    "                # in this case row_prev is x1 and row_now is x2\n",
    "                row1 = row_prev\n",
    "                row2 = row_now\n",
    "                \n",
    "            elif time_next - time_now > 0 and 0.000001 < time_next - time_now < 0.58:\n",
    "                # in this case row_now is x1 and row_next is x2\n",
    "                row1 = row_now\n",
    "                row2 = row_next\n",
    "            \n",
    "            x1, y1 = preprocess_image_valid_from_path(row1['image_path'].values[0], row1['speed'].values[0])\n",
    "            x2, y2 = preprocess_image_valid_from_path(row2['image_path'].values[0], row2['speed'].values[0])\n",
    "            \n",
    "            img_diff = opticalFlowDense(x1, x2)\n",
    "            img_diff = img_diff.reshape(1, img_diff.shape[0], img_diff.shape[1], img_diff.shape[2])\n",
    "            y = np.mean([y1, y2])\n",
    "            \n",
    "            speed = np.array([[y]])\n",
    "            yield img_diff, speed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Nvidia Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Architecture changed as a result of added dimensions\n",
    "* I added extra filters to try to capture more data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.core import Activation, Dropout, Flatten, Dense, Lambda\n",
    "from keras.layers import ELU\n",
    "from keras.optimizers import Adam\n",
    "import keras.backend.tensorflow_backend as KTF\n",
    "\n",
    "\n",
    "N_img_height = 66\n",
    "N_img_width = 220\n",
    "N_img_channels = 3\n",
    "def nvidia_model():\n",
    "    inputShape = (N_img_height, N_img_width, N_img_channels)\n",
    "\n",
    "    model = Sequential()\n",
    "    # normalization    \n",
    "    # perform custom normalization before lambda layer in network\n",
    "    model.add(Lambda(lambda x: x/ 127.5 - 1, input_shape = inputShape))\n",
    "\n",
    "    model.add(Convolution2D(24, (5, 5), \n",
    "                            strides=(2,2), \n",
    "                            padding = 'valid',\n",
    "                            kernel_initializer = 'he_normal',\n",
    "                            name = 'conv1'))\n",
    "    \n",
    "    \n",
    "    model.add(ELU())    \n",
    "    model.add(Convolution2D(36, (5, 5), \n",
    "                            strides=(2,2), \n",
    "                            padding = 'valid',\n",
    "                            kernel_initializer = 'he_normal',\n",
    "                            name = 'conv2'))\n",
    "    \n",
    "    model.add(ELU())    \n",
    "    model.add(Convolution2D(48, (5, 5), \n",
    "                            strides=(2,2), \n",
    "                            padding = 'valid',\n",
    "                            kernel_initializer = 'he_normal',\n",
    "                            name = 'conv3'))\n",
    "    model.add(ELU())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Convolution2D(64, (3, 3), \n",
    "                            strides = (1,1), \n",
    "                            padding = 'valid',\n",
    "                            kernel_initializer = 'he_normal',\n",
    "                            name = 'conv4'))\n",
    "    \n",
    "    model.add(ELU())              \n",
    "    model.add(Convolution2D(64, (3, 3), \n",
    "                            strides= (1,1), \n",
    "                            padding = 'valid',\n",
    "                            kernel_initializer = 'he_normal',\n",
    "                            name = 'conv5'))\n",
    "              \n",
    "              \n",
    "    model.add(Flatten(name = 'flatten'))\n",
    "    model.add(ELU())\n",
    "    model.add(Dense(100, kernel_initializer = 'he_normal', name = 'fc1'))\n",
    "    model.add(ELU())\n",
    "    model.add(Dense(50, kernel_initializer = 'he_normal', name = 'fc2'))\n",
    "    model.add(ELU())\n",
    "    model.add(Dense(10, kernel_initializer = 'he_normal', name = 'fc3'))\n",
    "    model.add(ELU())\n",
    "    \n",
    "    # do not put activation at the end because we want to exact output, not a class identifier\n",
    "    model.add(Dense(1, name = 'output', kernel_initializer = 'he_normal'))\n",
    "    \n",
    "    adam = Adam(lr=1e-4, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "    model.compile(optimizer = adam, loss = 'mse')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Define training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_size:  3754\n"
     ]
    }
   ],
   "source": [
    "val_size = len(valid_data.index)\n",
    "valid_generator = generate_validation_data(valid_data)\n",
    "BATCH = 16\n",
    "print('val_size: ', val_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Define model and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "filepath = 'model-weights-Vtest2.h5'\n",
    "earlyStopping = EarlyStopping(monitor='val_loss', \n",
    "                              patience=1, \n",
    "                              verbose=1, \n",
    "                              min_delta = 0.4,\n",
    "                              mode='min',)\n",
    "modelCheckpoint = ModelCheckpoint(filepath, \n",
    "                                  monitor = 'val_loss', \n",
    "                                  save_best_only = True, \n",
    "                                  mode = 'min', \n",
    "                                  verbose = 1,\n",
    "                                 save_weights_only = True)\n",
    "callbacks_list = [modelCheckpoint, earlyStopping]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "399/400 [============================>.] - ETA: 0s - loss: 122.9877  Epoch 00000: val_loss improved from inf to 51.50222, saving model to model-weights-Vtest2.h5\n",
      "400/400 [==============================] - 184s - loss: 122.7621 - val_loss: 51.5022\n",
      "Epoch 2/15\n",
      "399/400 [============================>.] - ETA: 0s - loss: 44.8858 Epoch 00001: val_loss improved from 51.50222 to 30.63284, saving model to model-weights-Vtest2.h5\n",
      "400/400 [==============================] - 179s - loss: 44.8587 - val_loss: 30.6328\n",
      "Epoch 3/15\n",
      "399/400 [============================>.] - ETA: 0s - loss: 32.4760 Epoch 00002: val_loss improved from 30.63284 to 22.48621, saving model to model-weights-Vtest2.h5\n",
      "400/400 [==============================] - 181s - loss: 32.4943 - val_loss: 22.4862\n",
      "Epoch 4/15\n",
      "399/400 [============================>.] - ETA: 0s - loss: 27.1846 Epoch 00003: val_loss improved from 22.48621 to 20.43839, saving model to model-weights-Vtest2.h5\n",
      "400/400 [==============================] - 179s - loss: 27.1416 - val_loss: 20.4384\n",
      "Epoch 5/15\n",
      "399/400 [============================>.] - ETA: 0s - loss: 22.3145 Epoch 00004: val_loss improved from 20.43839 to 19.54604, saving model to model-weights-Vtest2.h5\n",
      "400/400 [==============================] - 180s - loss: 22.2955 - val_loss: 19.5460\n",
      "Epoch 6/15\n",
      "399/400 [============================>.] - ETA: 0s - loss: 20.8801 Epoch 00005: val_loss improved from 19.54604 to 15.82865, saving model to model-weights-Vtest2.h5\n",
      "400/400 [==============================] - 180s - loss: 20.8506 - val_loss: 15.8286\n",
      "Epoch 7/15\n",
      "399/400 [============================>.] - ETA: 0s - loss: 17.7277 Epoch 00006: val_loss improved from 15.82865 to 13.29311, saving model to model-weights-Vtest2.h5\n",
      "400/400 [==============================] - 180s - loss: 17.7086 - val_loss: 13.2931\n",
      "Epoch 8/15\n",
      "399/400 [============================>.] - ETA: 0s - loss: 15.8495 Epoch 00007: val_loss improved from 13.29311 to 11.39541, saving model to model-weights-Vtest2.h5\n",
      "400/400 [==============================] - 180s - loss: 15.8255 - val_loss: 11.3954\n",
      "Epoch 9/15\n",
      "399/400 [============================>.] - ETA: 0s - loss: 13.9253 Epoch 00008: val_loss did not improve\n",
      "400/400 [==============================] - 180s - loss: 13.9185 - val_loss: 11.4606\n",
      "Epoch 10/15\n",
      "399/400 [============================>.] - ETA: 0s - loss: 13.3597 Epoch 00009: val_loss improved from 11.39541 to 9.34814, saving model to model-weights-Vtest2.h5\n",
      "400/400 [==============================] - 187s - loss: 13.3487 - val_loss: 9.3481\n",
      "Epoch 11/15\n",
      "399/400 [============================>.] - ETA: 0s - loss: 11.3732 Epoch 00010: val_loss improved from 9.34814 to 7.78135, saving model to model-weights-Vtest2.h5\n",
      "400/400 [==============================] - 182s - loss: 11.3540 - val_loss: 7.7813\n",
      "Epoch 12/15\n",
      "399/400 [============================>.] - ETA: 0s - loss: 10.0767 Epoch 00011: val_loss did not improve\n",
      "400/400 [==============================] - 180s - loss: 10.0579 - val_loss: 7.8646\n",
      "Epoch 13/15\n",
      "399/400 [============================>.] - ETA: 0s - loss: 9.2779  Epoch 00012: val_loss improved from 7.78135 to 6.95496, saving model to model-weights-Vtest2.h5\n",
      "400/400 [==============================] - 182s - loss: 9.2693 - val_loss: 6.9550\n",
      "Epoch 14/15\n",
      "399/400 [============================>.] - ETA: 0s - loss: 9.3849 Epoch 00013: val_loss improved from 6.95496 to 6.89117, saving model to model-weights-Vtest2.h5\n",
      "400/400 [==============================] - 184s - loss: 9.3826 - val_loss: 6.8912\n",
      "Epoch 15/15\n",
      "399/400 [============================>.] - ETA: 0s - loss: 8.4214  Epoch 00014: val_loss improved from 6.89117 to 5.54930, saving model to model-weights-Vtest2.h5\n",
      "400/400 [==============================] - 184s - loss: 8.4094 - val_loss: 5.5493\n",
      "<keras.callbacks.History object at 0x7f3725ccef60>\n"
     ]
    }
   ],
   "source": [
    "model = nvidia_model()\n",
    "train_size = len(train_data.index)\n",
    "train_generator = generate_training_data(train_data, BATCH)\n",
    "history = model.fit_generator(\n",
    "        train_generator, \n",
    "        steps_per_epoch = 400, \n",
    "        epochs = 15,\n",
    "    callbacks = callbacks_list,\n",
    "        verbose = 1,\n",
    "        validation_data = valid_generator,\n",
    "        validation_steps = val_size)\n",
    "\n",
    "print(history)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['val_loss', 'loss'])\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nGNMsSxDGGGOaZQnCGGNMs/4/GlmXWDoKIkIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f3725541518>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(history.history.keys())\n",
    "\n",
    "### plot the training and validation loss for each epoch\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model-v2test mean squared error loss 15 epochs')\n",
    "plt.ylabel('mean squared error loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['training set', 'validation set'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Optical Flow Approach MSE: ~5.5 for  epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Analysis\n",
    "* When passing the angle, and magnitude received from the optical flow calculation to the network my MSE is:\n",
    "* Method 1: Passing optical flow as RGB image only instead of the original image as well\n",
    "* In the end I went with the 7 epoch trained model because I had a good feeling it would be able to generalize well and was not overfit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "l2loss4epoch = mpimg.imread('./data/loss_L2_4epoch.png')\n",
    "plt.imshow(l2loss4epoch)\n",
    "plt.axis('off')\n",
    "plt.title('4 Epochs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "When passing in just the image, the MSE doesn't converge as well"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Train data preprocessing view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# random selection\n",
    "data = train_data\n",
    "random_images = []\n",
    "for i in range(20):\n",
    "    idx = np.random.randint(len(data))\n",
    "    bright_factor = 0.2 + np.random.uniform()\n",
    "    row = data.iloc[[idx]].reset_index()\n",
    "    x, y = preprocess_image_from_path(row['image_path'].values[0], row['speed'].values[0], bright_factor)\n",
    "    random_images.append((x, y))\n",
    "    \n",
    "plt.figure(figsize=(16, 10))\n",
    "gs1 = gridspec.GridSpec(4, 5)\n",
    "gs1.update(wspace = 0.01, hspace = 0.01)\n",
    "for idx, image in enumerate(random_images):\n",
    "    angle = 'speed: ' + str(image[1]) \n",
    "    ax1 = plt.subplot(gs1[idx])\n",
    "    ax1.axis('off')\n",
    "    plt.title(angle)\n",
    "    plt.imshow(image[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Validation data preprocessing view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# random selection\n",
    "data = train_data\n",
    "random_images = []\n",
    "for i in range(20):\n",
    "    idx = np.random.randint(len(data))\n",
    "    row = data.iloc[[idx]].reset_index()\n",
    "    x, y = preprocess_image_valid_from_path(row['image_path'].values[0], row['speed'].values[0])\n",
    "    random_images.append((x, y))\n",
    "    \n",
    "plt.figure(figsize=(16, 10))\n",
    "gs1 = gridspec.GridSpec(4, 5)\n",
    "gs1.update(wspace = 0.01, hspace = 0.01)\n",
    "for idx, image in enumerate(random_images):\n",
    "    angle = 'speed: ' + str(image[1]) \n",
    "    ax1 = plt.subplot(gs1[idx])\n",
    "    ax1.axis('off')\n",
    "    plt.title(angle)\n",
    "    plt.imshow(image[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### IDEAS: \n",
    "* Run forwards (img1 - img2) mean(speed)\n",
    "* Run backwards (img2 - img1) mean(speed)\n",
    "* Compute speed differential then apply prediction as: current_speed += speed_difference\n",
    "* speed_difference = xW + b\n",
    "* Optical Flow\n",
    "* Batch shuffler\n",
    "* Apply perspective transform\n",
    "* Sobely gradient \n",
    "* Gaussian blur"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Design considerations\n",
    "* Originally I generated a new brightness factor for each image, but that created some disturbances when I wanted to take the difference between both images so instead I used the same brightness augmentation for the current_frame and the next_frame. It works both ways though, it may have been better to make a random brightness augmentation because at one instant if our frame is under clear lighting, and the next frame has a shadow, we would not know how to consider that pixel difference. \n",
    "* I used a generator and yielded batches of my results, I did this so I didn't clog my memory stack while training my model\n",
    "* I took the input data and pushed the video images into a separate file and created a driving.csv file so I could use a pandas dataframe to read in each image path and only read in the image once I am in the generator. I could have just used moviepy and created a VideoFileClip and run all processing steps on each image, but I wouldn't have the same amount of control when testing out my preprocessing and data augmentation pipelines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Evaluate model performance\n",
    "* I choose to evaluate my performance with this code block instead of using model.evaluate so I didn't clog my stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "samples = 1000\n",
    "indices = [np.random.randint(1, len(data)-1) for i in range(samples)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "errors = []\n",
    "batch = []\n",
    "labels = []\n",
    "data = pd.read_csv('./data/driving.csv')\n",
    "for idx in indices:\n",
    "    row_now = data.iloc[[idx]].reset_index()\n",
    "    row_prev = data.iloc[[idx - 1]].reset_index()\n",
    "    row_next = data.iloc[[idx + 1]].reset_index()\n",
    "\n",
    "    # Find the 3 respective times to determine frame order (current -> next)\n",
    "\n",
    "    time_now = row_now['time'].values[0]\n",
    "    time_prev = row_prev['time'].values[0]\n",
    "    time_next = row_next['time'].values[0]\n",
    "\n",
    "    if time_now - time_prev > 0 and 0.0000001 < time_now - time_prev < 0.58: # 0.578111 is highest diff i have seen\n",
    "        # in this case row_prev is x1 and row_now is x2\n",
    "        row1 = row_prev\n",
    "        row2 = row_now\n",
    "\n",
    "    elif time_next - time_now > 0 and 0.0000001 < time_next - time_now < 0.58:\n",
    "        # in this case row_now is x1 and row_next is x2\n",
    "        row1 = row_now\n",
    "        row2 = row_next\n",
    "\n",
    "    x1, y1 = preprocess_image_valid_from_path(row1['image_path'].values[0], row1['speed'].values[0])\n",
    "    x2, y2 = preprocess_image_valid_from_path(row2['image_path'].values[0], row2['speed'].values[0])\n",
    "    img_diff = opticalFlowDense(x1, x2)\n",
    "    img_diff_reshaped = img_diff.reshape(1, img_diff.shape[0], img_diff.shape[1], img_diff.shape[2])\n",
    "    prediction = model.predict(img_diff_reshaped)\n",
    "    y = np.mean([y1, y2])\n",
    "    batch.append(img_diff)\n",
    "    labels.append(y)\n",
    "    errors.append(np.square(abs(y2 - prediction)))\n",
    "print('done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "# given an input image\n",
    "errors  = []\n",
    "data = pd.read_csv('./data/driving.csv')                    \n",
    "for idx in range(1, len(data.index) - 1):\n",
    "    row_now = data.iloc[[idx]].reset_index()\n",
    "    row_prev = data.iloc[[idx - 1]].reset_index()\n",
    "    row_next = data.iloc[[idx + 1]].reset_index()\n",
    "\n",
    "    # Find the 3 respective times to determine frame order (current -> next)\n",
    "\n",
    "    time_now = row_now['time'].values[0]\n",
    "    time_prev = row_prev['time'].values[0]\n",
    "    time_next = row_next['time'].values[0]\n",
    "\n",
    "    if time_now - time_prev > 0 and 0.0000001 < time_now - time_prev < 0.58: # 0.578111 is highest diff i have seen\n",
    "        # in this case row_prev is x1 and row_now is x2\n",
    "        row1 = row_prev\n",
    "        row2 = row_now\n",
    "\n",
    "    elif time_next - time_now > 0 and 0.0000001 < time_next - time_now < 0.58:\n",
    "        # in this case row_now is x1 and row_next is x2\n",
    "        row1 = row_now\n",
    "        row2 = row_next\n",
    "\n",
    "    x1, y1 = preprocess_image_valid_from_path(row1['image_path'].values[0], row1['speed'].values[0])\n",
    "    x2, y2 = preprocess_image_valid_from_path(row2['image_path'].values[0], row2['speed'].values[0])\n",
    "                                   \n",
    "    # reshape image difference to feed into model.predict\n",
    "    img_diff = opticalFlowDense(x1, x2)\n",
    "    img_diff_reshaped = img_diff.reshape(1, img_diff.shape[0], img_diff.shape[1], img_diff.shape[2])\n",
    "        \n",
    "    # grab the mean speed y to check our model against\n",
    "    y = np.mean([y1, y2])\n",
    "                                   \n",
    "    # note: y2 is the actual speed of the frame x2 which we will use for accurate prediction, even though\n",
    "    # our model is based on x1 and x2\n",
    "                                   \n",
    "    # TODO: retrain model to evaluate y2 instead of mean(y1, y2) and check differences\n",
    "                                   \n",
    "    prediction = model.predict(img_diff_reshaped)\n",
    "    error = abs(prediction - y2)\n",
    "    errors.append((idx, error))\n",
    "    \n",
    "\n",
    "          \n",
    "print('done!')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "* Evaluate on subset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### MSE for 14 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model = nvidia_model()\n",
    "model.load_weights('model-weights-Vtest.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Conclusion: Clearly the optical flow approach is the winner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Overlay prediction onto images and save to new directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def opticalFlowOverlay(image_current, image_next):\n",
    "    \"\"\"\n",
    "    input: image_current, image_next (RGB images)\n",
    "    output: mask\n",
    "    \"\"\"\n",
    "    feature_params = dict( maxCorners = 500,\n",
    "                       qualityLevel = 0.1,\n",
    "                       minDistance = 7,\n",
    "                       blockSize = 5 )\n",
    "    lk_params = dict( winSize  = (15, 15),\n",
    "                  maxLevel = 2,\n",
    "                  criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03))\n",
    "    \n",
    "    image_current_saved = np.copy(image_current)\n",
    "    image_next_saved = np.copy(image_next)\n",
    "    \n",
    "    image_current = cv2.cvtColor(image_current, cv2.COLOR_RGB2GRAY)\n",
    "    image_next = cv2.cvtColor(image_next, cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "    p0 = cv2.goodFeaturesToTrack(image_current, mask = None, **feature_params)\n",
    "\n",
    "    p1, st, err = cv2.calcOpticalFlowPyrLK(image_current, image_next, p0, None, **lk_params)\n",
    "\n",
    "\n",
    "    color = np.random.randint(0, 255, (100, 3))\n",
    "\n",
    "    mask = np.zeros_like(image_current)\n",
    "\n",
    "    # Select good points\n",
    "    good_new = p1[st == 1]\n",
    "    good_old = p0[st == 1]\n",
    "    for i, (new, old) in enumerate(zip(good_new, good_old)):\n",
    "        a, b = new.ravel() # flatten\n",
    "        c, d = old.ravel()\n",
    "        mask = cv2.arrowedLine(mask, (a,b), (c, d), color[i].tolist(), 1, 8)\n",
    "        \n",
    "        image_next = cv2.circle(image_next_saved, (a, b), 1, color[i].tolist(), -1)\n",
    "        image_next_fg = cv2.bitwise_and(image_next, image_next, mask = mask)\n",
    "        \n",
    "    dst = cv2.add(image_next, image_next_fg)\n",
    "    return dst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘./data/predict’: File exists\r\n"
     ]
    }
   ],
   "source": [
    "mkdir ./data/predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# given an input image\n",
    "\n",
    "data = pd.read_csv('./data/driving.csv')                    \n",
    "for idx in range(1, len(data.index) - 1):\n",
    "    row_now = data.iloc[[idx]].reset_index()\n",
    "    row_prev = data.iloc[[idx - 1]].reset_index()\n",
    "    row_next = data.iloc[[idx + 1]].reset_index()\n",
    "\n",
    "    # Find the 3 respective times to determine frame order (current -> next)\n",
    "\n",
    "    time_now = row_now['time'].values[0]\n",
    "    time_prev = row_prev['time'].values[0]\n",
    "    time_next = row_next['time'].values[0]\n",
    "\n",
    "    if time_now - time_prev > 0 and 0.0000001 < time_now - time_prev < 0.58: # 0.578111 is highest diff i have seen\n",
    "        # in this case row_prev is x1 and row_now is x2\n",
    "        row1 = row_prev\n",
    "        row2 = row_now\n",
    "\n",
    "    elif time_next - time_now > 0 and 0.0000001 < time_next - time_now < 0.58:\n",
    "        # in this case row_now is x1 and row_next is x2\n",
    "        row1 = row_now\n",
    "        row2 = row_next\n",
    "\n",
    "    x1, y1 = preprocess_image_valid_from_path(row1['image_path'].values[0], row1['speed'].values[0])\n",
    "    x2, y2 = preprocess_image_valid_from_path(row2['image_path'].values[0], row2['speed'].values[0])\n",
    "    img_diff = x1 - x2\n",
    "                                   \n",
    "    # reshape image difference to feed into model.predict\n",
    "    img_diff = opticalFlowDense(x1, x2)\n",
    "    img_diff_reshaped = img_diff.reshape(1, img_diff.shape[0], img_diff.shape[1], img_diff.shape[2])\n",
    "        \n",
    "    # grab the mean speed y to check our model against\n",
    "    y = np.mean([y1, y2])\n",
    "                                   \n",
    "    # note: y2 is the actual speed of the frame x2 which we will use for accurate prediction, even though\n",
    "    # our model is based on x1 and x2\n",
    "                                   \n",
    "    # TODO: retrain model to evaluate y2 instead of mean(y1, y2) and check differences\n",
    "                                   \n",
    "    prediction = model.predict(img_diff_reshaped)\n",
    "    error = abs(prediction - y2)\n",
    "    truth = y2\n",
    "                                       \n",
    "    predict_path = os.path.join('./data/predict/', str(idx) + '.jpg')\n",
    "                                   \n",
    "    # overwrite the prediction of y2 onto image x2\n",
    "    # save overwritten image x2 to new directory ./data/predict\n",
    "\n",
    "                                   \n",
    "    # Make a copy \n",
    "    dst = np.copy(x2)\n",
    "    \n",
    "    dst = opticalFlowOverlay(x1, x2) # This is a sparse optical flow overlay    \n",
    "    \n",
    "    # to write new image via openCV\n",
    "    offset = 10\n",
    "    FONT_SIZE = 0.3\n",
    "    THICKNESS = 1\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    cv2.putText(dst,'pred: ' + str(prediction[0][0])[:5],(5,offset), font, FONT_SIZE,(0,0,0), THICKNESS,cv2.LINE_AA)\n",
    "    cv2.putText(dst,'truth: ' + str(y2)[:5],(5,offset * 2), font, FONT_SIZE,(0,20,255), THICKNESS,cv2.LINE_AA)\n",
    "    cv2.putText(dst, 'error: ' + str(error[0][0])[:5], (5, offset*3),font, FONT_SIZE, (255, 0, 0), THICKNESS, cv2.LINE_AA)\n",
    "    \n",
    "    # convert back to BGR for writing\n",
    "    dst = cv2.cvtColor(dst, cv2.COLOR_RGB2BGR)\n",
    "    cv2.imwrite(predict_path, dst)\n",
    "    \n",
    "print('done!')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Create video from sequence of images\n",
    "* These videos are from dense optical flow method, where I compute the dense optical flow and convert that to an rgb image and pass it into the network. There is a video for the 30 epoch non-optical flow model which is on youtube [here](http://www.youtube.com/embed/WofBjhlaWqQ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video movie_vtest.mp4\n",
      "[MoviePy] Writing video movie_vtest.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8615/8615 [00:12<00:00, 664.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: movie_vtest.mp4 \n",
      "\n",
      "done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from moviepy.editor import VideoFileClip\n",
    "from moviepy.editor import ImageSequenceClip\n",
    "import glob\n",
    "import os\n",
    "\n",
    "images = ['./data/predict/' + str(i+1) + '.jpg' for i in range(0, 8614)]\n",
    "clip = ImageSequenceClip(images, fps=11.7552)\n",
    "clip.write_videofile(\"movie_vtest.mp4\", fps=11.7552)\n",
    "print('done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# rm -rf ./data/predict/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## L2 Video, 4 epochs OpticalFlow Method 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"960\" height=\"540\" controls>\n",
       "  <source src=\"movie_small_optical_dense_L2.mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format('movie_small_optical_dense_L2.mp4'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "This model is clearly overfit as you can see that the prediction is trying to predict high speeds during the freeway exit, but the ground truth happens to be set to a low speed. Here you can see that it attempts to predict the high speed but then it falls back down towards the ground truth speed. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### vtest Video: Optical Flow Method 2, 10 epochs MSE: 9.63"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format('movie_vtest.mp4'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### M3 Video Optical Flow Method, 16 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format('movie_small_optical_dense_M3.mp4'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "This one may have overfit just a bit, bit it looks really nice!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### For fun: Sparse Optical Flow Overlay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format('movie_small_optical_dense_M3_sparseoverlay.mp4'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reflections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* When I extract the image frames from the video file, I do so at a constant rate, splitting the 8616 frames evenly. In the ground truth dataset it is shown that images are not captured with a uniform sampling rate, so in each image, there is a slight error in the actual speed for that image. Meaning It will be unlikely that I can detect very rapid changes in speed.\n",
    "* I should have extracted the images using `ffmpeg -ss 0.5 -i inputfile.mp4 -t 1 -s 480x300 -f image2 imagefile.jpg`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Other Approaches\n",
    "* I notices this article: (http://nicolovaligi.com/car-speed-estimation-windshield-camera.html#Giachetti1999) and this code: (https://gist.github.com/nicolov/d010233ea8d35887c6ab47cca97d396f) that uses Optical Flow to for Car Speed estimation using a single windshield camera. I copied the code, modified some fields so it worked with my dataset and ran it to see what happens.\n",
    "* An interesting thing to note is that in this code he is using ground truth data to calibrate the `hf` factor. Still, once the car goes on the freeway and deals with speeds > 30mph it fails completely. \n",
    "I ran the code with my dataset, which you can see in <strong>OpticalFlow.ipynb </strong>, and here is the result I got.\n",
    "* When I ran this code, I cropped out a ton of the image, meaning I lost a bunch of data. There are points when driving that the background and scenery can help define changes in velocity. Such as the difference in a trees position from one frame to the next, for this reason I went with the CNN approach.\n",
    "* Next steps: My next step is to compute the optical flow for each (current_image, next_frame) and feed that into my network as well. This way I can have the best of both worlds. Stay tuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "result = mpimg.imread('./data/optical_flow_result.png')\n",
    "plt.imshow(result)\n",
    "plt.axis('off')\n",
    "plt.title('Optical Flow Analysis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### <font color = 'green'>Optical Flow</font> vs <font color = 'blue'>CNN</font> Analysis\n",
    "* <font color = 'green'>3/4 in to the video, when we are absolutely on the freeway optical flow analysis tanks </font>\n",
    "* <font color = 'blue'>In the CNN approach, we did pretty well 3/4ths into the video, I would say that the CNN's estimation was better than a pure optical flow approach, (assuming I did not overfit the dataset). The optical flow approach performs poorly on the freeway in the last 3/4 of the video while the convnet seems to perform better</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Future considerations\n",
    "* If I had more time I would finish my DeepVO implementation [DeepVO](https://arxiv.org/pdf/1611.06069.pdf), which I started to write but did not finish. You can see DeepVO in <strong>DeepVO.ipynb</strong>\n",
    "* I would also try to implement [DeepFlow](http://www.cv-foundation.org/openaccess/content_iccv_2013/papers/Weinzaepfel_DeepFlow_Large_Displacement_2013_ICCV_paper.pdf) which claims to have great performance. \n",
    "* I would also consider trying [FlowNet](https://arxiv.org/pdf/1504.06852.pdf) and I would use this as a [guide] (https://github.com/ClementPinard/FlowNetPytorch)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
