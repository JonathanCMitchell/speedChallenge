{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.gridspec as gridspec\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Data Acquisition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Create DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "* Create dataframe with image_path, time(seconds) and speed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "* In the video given, we have ~344 (5min 44s) seconds of video. \n",
    "* Our ground truth labels correspond to a video that is 12m 12s (~732seconds). \n",
    "* We only have a portion of that video. \n",
    "* It appears that our framerate <strong>~ 13 fps </strong>. (4459 frames * (1 second / 13frames) = 344 seconds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4459"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./data/driving.csv')\n",
    "df.head(10)\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Plot Speeds vs Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgkAAAFyCAYAAAB/b0lnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIiIicvT/AVfCvj/DgRgeAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f8efaf0a0b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "times = np.asarray(df['time'], dtype = np.float32)\n",
    "speeds = np.asarray(df['speed'], dtype=np.float32)\n",
    "plt.plot(times, speeds, 'r-')\n",
    "plt.title('Speed vs Time')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_path</th>\n",
       "      <th>time</th>\n",
       "      <th>speed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4454</th>\n",
       "      <td>./data/IMG/344.3211498260498.jpg</td>\n",
       "      <td>344.321150</td>\n",
       "      <td>27.928958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4455</th>\n",
       "      <td>./data/IMG/344.37305998802185.jpg</td>\n",
       "      <td>344.373060</td>\n",
       "      <td>27.938640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4456</th>\n",
       "      <td>./data/IMG/344.5106108188629.jpg</td>\n",
       "      <td>344.510611</td>\n",
       "      <td>27.932405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4457</th>\n",
       "      <td>./data/IMG/344.5854048728943.jpg</td>\n",
       "      <td>344.585405</td>\n",
       "      <td>27.927574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4458</th>\n",
       "      <td>./data/IMG/344.63681387901306.jpg</td>\n",
       "      <td>344.636814</td>\n",
       "      <td>27.847842</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             image_path        time      speed\n",
       "4454   ./data/IMG/344.3211498260498.jpg  344.321150  27.928958\n",
       "4455  ./data/IMG/344.37305998802185.jpg  344.373060  27.938640\n",
       "4456   ./data/IMG/344.5106108188629.jpg  344.510611  27.932405\n",
       "4457   ./data/IMG/344.5854048728943.jpg  344.585405  27.927574\n",
       "4458  ./data/IMG/344.63681387901306.jpg  344.636814  27.847842"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Shuffle Pairs and Train Test Split\n",
    "* This function is a batch shuffler, \n",
    "* There is a 20% chance to add the row to validation data, other wise it will be train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def batch_shuffle(dframe):\n",
    "    \"\"\"\n",
    "    Randomly shuffle pairs of rows in the dataframe, separates train and validation data\n",
    "    generates a uniform random variable 0->9, gives 20% chance to append to valid data, otherwise train_data\n",
    "    return tuple (train_data, valid_data) dataframes\n",
    "    \"\"\"\n",
    "    train_data = pd.DataFrame()\n",
    "    valid_data = pd.DataFrame()\n",
    "    for i in range(len(dframe) - 1):\n",
    "        idx1 = np.random.randint(len(dframe) - 1)\n",
    "        idx2 = idx1 + 1\n",
    "        \n",
    "        row1 = dframe.iloc[[idx1]].reset_index()\n",
    "        row2 = dframe.iloc[[idx2]].reset_index()\n",
    "        \n",
    "        randInt = np.random.randint(9)\n",
    "        if 0 <= randInt <= 1:\n",
    "            valid_frames = [valid_data, row1, row2]\n",
    "            valid_data = pd.concat(valid_frames, axis = 0, join = 'outer', ignore_index=False)\n",
    "        if randInt >= 2:\n",
    "            train_frames = [train_data, row1, row2]\n",
    "            train_data = pd.concat(train_frames, axis = 0, join = 'outer', ignore_index=False)\n",
    "    return train_data, valid_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train_data, valid_data = batch_shuffle(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_data:  2016\n",
      "train_data:  6900\n"
     ]
    }
   ],
   "source": [
    "print('valid_data: ', len(valid_data))\n",
    "print('train_data: ', len(train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>image_path</th>\n",
       "      <th>time</th>\n",
       "      <th>speed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2708</td>\n",
       "      <td>./data/IMG/198.37479376792908.jpg</td>\n",
       "      <td>198.374794</td>\n",
       "      <td>5.350917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2709</td>\n",
       "      <td>./data/IMG/198.49412178993225.jpg</td>\n",
       "      <td>198.494122</td>\n",
       "      <td>5.383622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>454</td>\n",
       "      <td>./data/IMG/32.40308094024658.jpg</td>\n",
       "      <td>32.403081</td>\n",
       "      <td>7.269643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>455</td>\n",
       "      <td>./data/IMG/32.48107290267944.jpg</td>\n",
       "      <td>32.481073</td>\n",
       "      <td>7.271189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>790</td>\n",
       "      <td>./data/IMG/56.99446487426758.jpg</td>\n",
       "      <td>56.994465</td>\n",
       "      <td>10.079502</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                         image_path        time      speed\n",
       "0   2708  ./data/IMG/198.37479376792908.jpg  198.374794   5.350917\n",
       "0   2709  ./data/IMG/198.49412178993225.jpg  198.494122   5.383622\n",
       "0    454   ./data/IMG/32.40308094024658.jpg   32.403081   7.269643\n",
       "0    455   ./data/IMG/32.48107290267944.jpg   32.481073   7.271189\n",
       "0    790   ./data/IMG/56.99446487426758.jpg   56.994465  10.079502"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def change_brightness(image, bright_factor):\n",
    "    \"\"\"\n",
    "    Augments the brightness of the image by multiplying the saturation by a uniform random variable\n",
    "    Input: image (RGB)\n",
    "    returns: image with brightness augmentation\n",
    "    \"\"\"\n",
    "    \n",
    "    hsv_image = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n",
    "    # perform brightness augmentation only on the second channel\n",
    "    hsv_image[:,:,2] = hsv_image[:,:,2] * bright_factor\n",
    "    \n",
    "    # change back to RGB\n",
    "    image_rgb = cv2.cvtColor(hsv_image, cv2.COLOR_HSV2RGB)\n",
    "    return image_rgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Perspective Transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "* I did not end up applying the perspective transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Test optical flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# row1 = train_data.iloc[[14]].reset_index()\n",
    "# row2 = train_data.iloc[[15]].reset_index()\n",
    "\n",
    "# time1 = row1['time'].values[0]\n",
    "# time2 = row2['time'].values[0]\n",
    "\n",
    "# image_current = mpimg.imread(row1['image_path'].values[0])\n",
    "# image_next = mpimg.imread(row2['image_path'].values[0])\n",
    "\n",
    "# # it will be RGB in pipeline \n",
    "# image_current = preprocess_image(image_current)\n",
    "# image_next = preprocess_image(image_next)\n",
    "\n",
    "# image_current_saved = np.copy(image_current)\n",
    "# image_next_saved = np.copy(image_next)\n",
    "\n",
    "\n",
    "# image_current = cv2.cvtColor(image_current, cv2.COLOR_RGB2GRAY)\n",
    "# image_next = cv2.cvtColor(image_next, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "\n",
    "# p0 = cv2.goodFeaturesToTrack(image_current, mask = None, **feature_params)\n",
    "\n",
    "# # plt.imshow(image_current, cmap='gray')\n",
    "# # plt.imshow(image_next, cmap='gray')\n",
    "# p1, st, err = cv2.calcOpticalFlowPyrLK(image_current, image_next, p0, None, **lk_params)\n",
    "\n",
    "\n",
    "\n",
    "# # print('::', p0 - p1)\n",
    "# color = np.random.randint(0, 255, (100, 3))\n",
    "\n",
    "# mask = np.zeros_like(image_current)\n",
    "\n",
    "# # Select good points\n",
    "# good_new = p1[st == 1]\n",
    "# good_old = p0[st == 1]\n",
    "# for i, (new, old) in enumerate(zip(good_new, good_old)):\n",
    "#     a, b = new.ravel() # flatten\n",
    "#     c, d = old.ravel()\n",
    "#     mask = cv2.line(mask, (a,b), (c, d), color[i].tolist(), 2)\n",
    "    \n",
    "#     image_next = cv2.circle(image_next_saved, (a, b), 1, color[i].tolist(), -1)\n",
    "#     image_next_fg = cv2.bitwise_and(image_next, image_next, mask = mask)\n",
    "#     dst = cv2.add(image_next, image_next_fg)\n",
    "# print('dst: ', dst.shape)\n",
    "# plt.imshow(dst)\n",
    "# # img = cv2.addWeighted(mask, 0.7,image_next, 0.3, 0)\n",
    "# # plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def opticalFlowOverlay(image_current, image_next):\n",
    "    \"\"\"\n",
    "    input: image_current, image_next (RGB images)\n",
    "    output: mask\n",
    "    \"\"\"\n",
    "    \n",
    "    image_current_saved = np.copy(image_current)\n",
    "    image_next_saved = np.copy(image_next)\n",
    "    \n",
    "    image_current = cv2.cvtColor(image_current, cv2.COLOR_RGB2GRAY)\n",
    "    image_next = cv2.cvtColor(image_next, cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "    p0 = cv2.goodFeaturesToTrack(image_current, mask = None, **feature_params)\n",
    "\n",
    "    p1, st, err = cv2.calcOpticalFlowPyrLK(image_current, image_next, p0, None, **lk_params)\n",
    "\n",
    "\n",
    "    color = np.random.randint(0, 255, (100, 3))\n",
    "\n",
    "    mask = np.zeros_like(image_current)\n",
    "\n",
    "    # Select good points\n",
    "    good_new = p1[st == 1]\n",
    "    good_old = p0[st == 1]\n",
    "    for i, (new, old) in enumerate(zip(good_new, good_old)):\n",
    "        a, b = new.ravel() # flatten\n",
    "        c, d = old.ravel()\n",
    "        mask = cv2.arrowedLine(mask, (a,b), (c, d), color[i].tolist(), 1, 8)\n",
    "        \n",
    "        image_next = cv2.circle(image_next_saved, (a, b), 1, color[i].tolist(), -1)\n",
    "        image_next_fg = cv2.bitwise_and(image_next, image_next, mask = mask)\n",
    "        \n",
    "    dst = cv2.add(image_next, image_next_fg)\n",
    "    return dst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Optical Flow Dense\n",
    "* Two strategies\n",
    "* Strategy 1: get optical flow ang, magnitude, convert HSV to RGB and throw that image into the network\n",
    "* Strategy 2: get optical flow ang, magnitude, convert HSV to RGB then overlay ontop of original image and throw that into the network as RGB\n",
    "* Strategy 3: get optical flow parameters, ang, magnitude and expand dimensions of original image so you throw H x W x R x G x B x Ang x Magnitude into the network\n",
    "* Strategy 4: send in the flow differences as RGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def opticalFlowDense(image_current, image_next):\n",
    "    \"\"\"\n",
    "    input: image_current, image_next (RGB images)\n",
    "    output: image_difference as data (R,G,B,A,M)\n",
    "    \"\"\"\n",
    "    \n",
    "    image_current_saved = np.copy(image_current)\n",
    "    image_next_saved = np.copy(image_next)\n",
    "    \n",
    "    image_current = cv2.cvtColor(image_current, cv2.COLOR_RGB2GRAY)\n",
    "    image_next = cv2.cvtColor(image_next, cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "    \n",
    "    data = np.zeros((66, 220, 5))\n",
    "    \n",
    " \n",
    "    # Flow Parameters\n",
    "    flow_mat = cv2.CV_32FC2\n",
    "    image_scale = 0.4\n",
    "    nb_images = 1\n",
    "    win_size = 15\n",
    "    nb_iterations = 2\n",
    "    deg_expansion = 5\n",
    "    STD = 1.3\n",
    "    extra = 0\n",
    "\n",
    "    # obtain dense optical flow paramters\n",
    "    flow = cv2.calcOpticalFlowFarneback(image_current, image_next,  \n",
    "                                        flow_mat, \n",
    "                                        image_scale, \n",
    "                                        nb_images, \n",
    "                                        win_size, \n",
    "                                        nb_iterations, \n",
    "                                        deg_expansion, \n",
    "                                        STD, \n",
    "                                        0)\n",
    "                                        \n",
    "        \n",
    "    # convert from cartesian to polar\n",
    "    mag, ang = cv2.cartToPolar(flow[..., 0], flow[..., 1])  \n",
    "    mag_norm = cv2.normalize(mag,None,0,255,cv2.NORM_MINMAX)\n",
    "        \n",
    "    # get red differences\n",
    "    red_diff = image_current_saved[:,:,0] - image_next_saved[:,:,0]\n",
    "    \n",
    "    # get green differences\n",
    "    greed_diff = image_current_saved[:,:,1] - image_next_saved[:,:,1]\n",
    "    \n",
    "    # get blue differences\n",
    "    blue_diff = image_current_saved[:,:,2] - image_next_saved[:,:,2]\n",
    "    \n",
    "    # get hue for data\n",
    "    ang = ang * 180 / np.pi / 2\n",
    "    \n",
    "    \n",
    "    # ang normalize\n",
    "    ang = ang * (255/ 180)\n",
    "    \n",
    "    data[:,:,0] = red_diff\n",
    "    data[:,:,1] = green_diff\n",
    "    data[:,:,2] = blue_diff\n",
    "    data[:,:,3] = ang\n",
    "    data[:,:,4] = mag_norm\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# row1 = train_data.iloc[[20]].reset_index()\n",
    "# row2 = train_data.iloc[[21]].reset_index()\n",
    "\n",
    "# print(row1['time'].values[0])\n",
    "# print(row2['time'].values[0])\n",
    "\n",
    "# image_current = mpimg.imread(row1['image_path'].values[0])\n",
    "# image_next = mpimg.imread(row2['image_path'].values[0])\n",
    "\n",
    "# image_current = preprocess_image(image_current)\n",
    "# image_next = preprocess_image(image_next)\n",
    "\n",
    "# dstt = opticalFlowDense(image_current, image_next)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def apply_perspective_transform(image):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "feature_params = dict( maxCorners = 500,\n",
    "                       qualityLevel = 0.1,\n",
    "                       minDistance = 7,\n",
    "                       blockSize = 5 )\n",
    "lk_params = dict( winSize  = (15, 15),\n",
    "                  maxLevel = 2,\n",
    "                  criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def OpticalFlow(image_current, image_next):\n",
    "    \"\"\"\n",
    "    inputs: image1: image_current, image2: image_next (as RGB)\n",
    "    \n",
    "    returns flow_direction, flow_magnitude\n",
    "    \"\"\"\n",
    "    image_current = cv2.cvtColor(image_current, cv2.COLOR_RGB2GRAY)\n",
    "    image_next = cv2.cvtColor(image_next, cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "    p0 = cv2.goodFeaturesToTrack(image_current, mask = None, **feature_params)\n",
    "    \n",
    "    p1, st, err = cv2.calcOpticalFlowPyrLK(image_current, image_next, p0, None, **lk_params)\n",
    "\n",
    "    good_new = p1[st == 1]\n",
    "    good_old = p0[st == 1]\n",
    "\n",
    "    direction = np.arctan(good_new.ravel(), good_old.ravel())\n",
    "    magnitude = np.sqrt(good_new.ravel()**2, good_old.ravel()** 2)\n",
    "    \n",
    "    return direction, magnitude"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Expand dims to add optical flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def preprocess_image(image):\n",
    "    \"\"\"\n",
    "    preprocesses the image\n",
    "    \n",
    "    input: image (480 (y), 640 (x), 3) RGB\n",
    "    output: image (shape is (220, 66, 3) as RGB)\n",
    "    \n",
    "    This stuff is performed on my validation data and my training data\n",
    "    Process: \n",
    "             1) Cropping out black spots\n",
    "             2) Perspective transform\n",
    "             3) resize to (220, 66, 3) if not done so already from perspective transform\n",
    "    \"\"\"\n",
    "    # Crop out sky (top) (100px) and black right part (-90px)\n",
    "    image_cropped = image[100:440, :-90] # -> (380, 550, 3)\n",
    "    # TODO: Write perspective transform \n",
    "#     perspective = apply_perspective_transform(image_cropped)\n",
    "    \n",
    "    image = cv2.resize(image_cropped, (220, 66), interpolation = cv2.INTER_AREA)\n",
    "    \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def preprocess_image_valid_from_path(image_path, speed):\n",
    "    img = cv2.imread(image_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = preprocess_image(img)\n",
    "    return img, speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def preprocess_image_from_path(image_path, speed, bright_factor):\n",
    "    img = cv2.imread(image_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    img = change_brightness(img, bright_factor)\n",
    "    \n",
    "    # compute optical flow and append it to the image as 4th and 5th dimension\n",
    "    \n",
    "            \n",
    "    img = preprocess_image(img)\n",
    "    return img, speed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Generators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Train Generator\n",
    "* This is used to yield train batches of image_difference and average speed. \n",
    "* We pick a random spot in the training dataset, between 1 and length - 1\n",
    "* determine the relationship between 3 frames\n",
    "* locate the current_frame and the next_frame\n",
    "* Take the difference between them and their average speed and build batches with that information\n",
    "* Then shuffle the batch and yield it, which will then be fed into the network\n",
    "* Generators allow me to not clog my memory stack so I can perform these operations on 16 (`BATCH` size) at a time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def generate_training_data(data, batch_size = 32):\n",
    "    image_batch = np.zeros((batch_size, 66, 220, 3)) # nvidia input params\n",
    "    label_batch = np.zeros((batch_size))\n",
    "    while True:\n",
    "        for i in range(batch_size):\n",
    "            # generate a random index with a uniform random distribution from 1 to len - 1\n",
    "            idx = np.random.randint(1, len(data) - 1)\n",
    "            \n",
    "            \n",
    "            # Generate a random bright factor to apply to both images\n",
    "            bright_factor = 0.2 + np.random.uniform()\n",
    "            \n",
    "            row_now = data.iloc[[idx]].reset_index()\n",
    "            row_prev = data.iloc[[idx - 1]].reset_index()\n",
    "            row_next = data.iloc[[idx + 1]].reset_index()\n",
    "            \n",
    "            # Find the 3 respective times to determine frame order (current -> next)\n",
    "            \n",
    "            time_now = row_now['time'].values[0]\n",
    "            time_prev = row_prev['time'].values[0]\n",
    "            time_next = row_next['time'].values[0]\n",
    "            \n",
    "            if time_now - time_prev > 0 and 0.0000001 < time_now - time_prev < 0.58: # 0.578111 is highest diff i have seen\n",
    "                # in this case row_prev is x1 and row_now is x2\n",
    "                row1 = row_prev\n",
    "                row2 = row_now\n",
    "                \n",
    "            elif time_next - time_now > 0 and 0.0000001 < time_next - time_now < 0.58:\n",
    "                # in this case row_now is x1 and row_next is x2\n",
    "                row1 = row_now\n",
    "                row2 = row_next\n",
    "                \n",
    "                # Use this to find outliers\n",
    "            else:\n",
    "                print('time_now is not next or prev: ', time_now)\n",
    "                print('time_prev is :', time_prev)\n",
    "                print('time_next is: ', time_next)\n",
    "                \n",
    "                print('\\n diff: now  - prev \\t', time_now - time_prev)\n",
    "                print('\\n diff: next - now: \\t', time_next - time_now)\n",
    "            \n",
    "            \n",
    "            x1, y1 = preprocess_image_from_path(row1['image_path'].values[0],\n",
    "                                                row1['speed'].values[0],\n",
    "                                               bright_factor)\n",
    "            \n",
    "            # preprocess another image\n",
    "            x2, y2 = preprocess_image_from_path(row2['image_path'].values[0], \n",
    "                                                row2['speed'].values[0],\n",
    "                                               bright_factor)\n",
    "           \n",
    "            # subtract image features\n",
    "            x = x1 - x2\n",
    "            \n",
    "            # compute optical flow send in images as RGB\n",
    "            data = opticalFlowDense(x1, x2)\n",
    "            \n",
    "            # example image dimensions to contain flow_direction and flow_magnitude\n",
    "            \n",
    "            # calculate mean speed\n",
    "            y = np.mean([y1, y2])\n",
    "            \n",
    "            image_batch[i] = data\n",
    "            label_batch[i] = y\n",
    "            \n",
    "        # Shuffle the pairs before they get fed into the network\n",
    "        yield shuffle(image_batch, label_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Validation Generator\n",
    "* This is used to yield validation image_difference and average speed. \n",
    "* We pick iterate through the validation data, determine the relationship between 3 frames, locate the current_frame and the next_frame. Take the difference between them and their average speed and feed that into the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def generate_validation_data(data):\n",
    "    while True:\n",
    "        for idx in range(1, len(data) - 1): # start from the second row because we may try to grab it and need its prev to be in bounds\n",
    "            row_now = data.iloc[[idx]].reset_index()\n",
    "            row_prev = data.iloc[[idx - 1]].reset_index()\n",
    "            row_next = data.iloc[[idx + 1]].reset_index()\n",
    "            \n",
    "            # Find the 3 respective times to determine frame order (current -> next)\n",
    "            \n",
    "            time_now = row_now['time'].values[0]\n",
    "            time_prev = row_prev['time'].values[0]\n",
    "            time_next = row_next['time'].values[0]\n",
    "            \n",
    "            if time_now - time_prev > 0 and 0.0000001 < time_now - time_prev < 0.58:\n",
    "                # in this case row_prev is x1 and row_now is x2\n",
    "                row1 = row_prev\n",
    "                row2 = row_now\n",
    "                \n",
    "            elif time_next - time_now > 0 and 0.000001 < time_next - time_now < 0.58:\n",
    "                # in this case row_now is x1 and row_next is x2\n",
    "                row1 = row_now\n",
    "                row2 = row_next\n",
    "            \n",
    "            x1, y1 = preprocess_image_valid_from_path(row1['image_path'].values[0], row1['speed'].values[0])\n",
    "            x2, y2 = preprocess_image_valid_from_path(row2['image_path'].values[0], row2['speed'].values[0])\n",
    "            \n",
    "            img_diff = opticalFlowDense(x1, x2)\n",
    "            img_diff = img_diff.reshape(1, img_diff.shape[0], \n",
    "                                        img_diff.shape[1], \n",
    "                                        img_diff.shape[2],\n",
    "                                       img_diff.shape[3],\n",
    "                                       img_diff.shape[4])\n",
    "            \n",
    "            y = np.mean([y1, y2])\n",
    "            \n",
    "            speed = np.array([[y]])\n",
    "            yield img_diff, speed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Nvidia Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Architecture changed as a result of added dimensions\n",
    "* I added extra filters to try to capture more data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.core import Activation, Dropout, Flatten, Dense, Lambda\n",
    "from keras.layers import ELU\n",
    "from keras.optimizers import Adam\n",
    "tf.python.control_flow_ops = tf\n",
    "\n",
    "N_img_height = 66\n",
    "N_img_width = 220\n",
    "N_img_channels = 5\n",
    "def nvidia_model():\n",
    "    inputShape = (N_img_height, N_img_width, N_img_channels)\n",
    "\n",
    "    model = Sequential()\n",
    "    # normalization\n",
    "    # switch to normalize (0, 1) max min style\n",
    "    \n",
    "    # perform custom normalization before lambda layer in network\n",
    "    model.add(Lambda(lambda x: x/ 127.5 - 1, input_shape = inputShape))\n",
    "\n",
    "    model.add(Convolution2D(24, 5, 5, \n",
    "                            subsample=(2,2), \n",
    "                            border_mode = 'valid',\n",
    "                            init = 'he_normal',\n",
    "                            input_shape = inputShape,\n",
    "                            name = 'conv1'))\n",
    "    \n",
    "    model.add(ELU())    \n",
    "    model.add(Convolution2D(36, 5, 5, \n",
    "                            subsample=(2,2), \n",
    "                            border_mode = 'valid',\n",
    "                            init = 'he_normal',\n",
    "                            name = 'conv2'))\n",
    "    \n",
    "    model.add(ELU())    \n",
    "    model.add(Convolution2D(48, 5, 5, \n",
    "                            subsample=(2,2), \n",
    "                            border_mode = 'valid',\n",
    "                            init = 'he_normal',\n",
    "                            name = 'conv3'))\n",
    "    model.add(ELU())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Convolution2D(64, 3, 3, \n",
    "                            subsample = (1,1), \n",
    "                            border_mode = 'valid',\n",
    "                            init = 'he_normal', #gaussian init\n",
    "                            name = 'conv4'))\n",
    "    \n",
    "    model.add(ELU())              \n",
    "    model.add(Convolution2D(64, 3, 3, \n",
    "                            subsample= (1,1), \n",
    "                            border_mode = 'valid',\n",
    "                            init = 'he_normal',\n",
    "                            name = 'conv5'))\n",
    "              \n",
    "              \n",
    "    model.add(Flatten(name = 'flatten'))\n",
    "    model.add(ELU())\n",
    "    model.add(Dense(100, init = 'he_normal', name = 'fc1'))\n",
    "    model.add(ELU())\n",
    "    model.add(Dense(50, init = 'he_normal', name = 'fc2'))\n",
    "    model.add(ELU())\n",
    "    model.add(Dense(10, init = 'he_normal', name = 'fc3'))\n",
    "    model.add(ELU())\n",
    "    \n",
    "    # do not put activation at the end because we want to exact output, not a class identifier\n",
    "    model.add(Dense(1, name = 'output', init = 'he_normal'))\n",
    "    \n",
    "    adam = Adam(lr=1e-4, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "    model.compile(optimizer = adam, loss = 'mse')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Define training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_size:  2016\n"
     ]
    }
   ],
   "source": [
    "val_size = len(valid_data.index)\n",
    "valid_generator = generate_validation_data(valid_data)\n",
    "BATCH = 16\n",
    "print('val_size: ', val_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Define model and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'generate_training_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-131482d3408a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtrain_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mtrain_generator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_training_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBATCH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     history = model.fit_generator(\n\u001b[1;32m      6\u001b[0m             \u001b[0mtrain_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'generate_training_data' is not defined"
     ]
    }
   ],
   "source": [
    "model = nvidia_model()\n",
    "train_size = len(train_data.index)\n",
    "for i in range(3):\n",
    "    train_generator = generate_training_data(train_data, BATCH)\n",
    "    history = model.fit_generator(\n",
    "            train_generator, \n",
    "            samples_per_epoch = 20480, # try putting the whole thing in here in the future\n",
    "            nb_epoch = 6,\n",
    "            validation_data = valid_generator,\n",
    "            nb_val_samples = val_size)\n",
    "    print(history)\n",
    "    \n",
    "    model.save_weights('model-weights-RGBAM.h5')\n",
    "    model.save('model-RGBAM.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print(history.history.keys())\n",
    "\n",
    "### plot the training and validation loss for each epoch\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model mean squared error loss 18 epochs')\n",
    "plt.ylabel('mean squared error loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['training set', 'validation set'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Analysis\n",
    "* With 6 epochs I noticed that I started to overfit my dataset when the validation loss started oscillating\n",
    "* 5 loops 6 epochs: MSE (train):1.6149, MSE (valid): 20.3356\n",
    "* 3 loops 6 epochs: MSE (train): , MSE (valid): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "loop5epoch6 = mpimg.imread('./data/5Loops6EpochsDiag.png')\n",
    "plt.imshow(loop5epoch6)\n",
    "plt.axis('off')\n",
    "plt.title('30 Epochs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Train data preprocessing view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# random selection\n",
    "data = train_data\n",
    "random_images = []\n",
    "for i in range(20):\n",
    "    idx = np.random.randint(len(data))\n",
    "    bright_factor = 0.2 + np.random.uniform()\n",
    "    row = data.iloc[[idx]].reset_index()\n",
    "    x, y = preprocess_image_from_path(row['image_path'].values[0], row['speed'].values[0], bright_factor)\n",
    "    random_images.append((x, y))\n",
    "    \n",
    "plt.figure(figsize=(16, 10))\n",
    "gs1 = gridspec.GridSpec(4, 5)\n",
    "gs1.update(wspace = 0.01, hspace = 0.01)\n",
    "for idx, image in enumerate(random_images):\n",
    "    angle = 'speed: ' + str(image[1]) \n",
    "    ax1 = plt.subplot(gs1[idx])\n",
    "    ax1.axis('off')\n",
    "    plt.title(angle)\n",
    "    plt.imshow(image[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Validation data preprocessing view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# random selection\n",
    "data = train_data\n",
    "random_images = []\n",
    "for i in range(20):\n",
    "    idx = np.random.randint(len(data))\n",
    "    row = data.iloc[[idx]].reset_index()\n",
    "    x, y = preprocess_image_valid_from_path(row['image_path'].values[0], row['speed'].values[0])\n",
    "    random_images.append((x, y))\n",
    "    \n",
    "plt.figure(figsize=(16, 10))\n",
    "gs1 = gridspec.GridSpec(4, 5)\n",
    "gs1.update(wspace = 0.01, hspace = 0.01)\n",
    "for idx, image in enumerate(random_images):\n",
    "    angle = 'speed: ' + str(image[1]) \n",
    "    ax1 = plt.subplot(gs1[idx])\n",
    "    ax1.axis('off')\n",
    "    plt.title(angle)\n",
    "    plt.imshow(image[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### IDEAS: \n",
    "* Run forwards (img1 - img2) mean(speed)\n",
    "* Run backwards (img2 - img1) mean(speed)\n",
    "* Compute speed differential then apply prediction as: current_speed += speed_difference\n",
    "* speed_difference = xW + b\n",
    "\n",
    "* Batch shuffler\n",
    "* Apply perspective transform\n",
    "* Sobely gradient \n",
    "* Gaussian blur"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Design considerations\n",
    "* Originally I generated a new brightness factor for each image, but that created some disturbances when I wanted to take the difference between both images so instead I used the same brightness augmentation for the current_frame and the next_frame. It works both ways though, it may have been better to make a random brightness augmentation because at one instant if our frame is under clear lighting, and the next frame has a shadow, we would not know how to consider that pixel difference. \n",
    "* I used a generator and yielded batches of my results, I did this so I didn't clog my memory stack while training my model\n",
    "* I took the input data and pushed the video images into a separate file and created a driving.csv file so I could use a pandas dataframe to read in each image path and only read in the image once I am in the generator. I could have just used moviepy and created a VideoFileClip and run all processing steps on each image, but I wouldn't have the same amount of control when testing out my preprocessing and data augmentation pipelines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Evaluate model performance\n",
    "* I choose to evaluate my performance with this code block instead of using model.evaluate so I didn't clog my stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "samples = 1000\n",
    "indices = [np.random.randint(1, 4430) for i in range(samples)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "errors = []\n",
    "batch = []\n",
    "labels = []\n",
    "data = pd.read_csv('./data/driving.csv')\n",
    "for idx in indices:\n",
    "    row_now = data.iloc[[idx]].reset_index()\n",
    "    row_prev = data.iloc[[idx - 1]].reset_index()\n",
    "    row_next = data.iloc[[idx + 1]].reset_index()\n",
    "\n",
    "    # Find the 3 respective times to determine frame order (current -> next)\n",
    "\n",
    "    time_now = row_now['time'].values[0]\n",
    "    time_prev = row_prev['time'].values[0]\n",
    "    time_next = row_next['time'].values[0]\n",
    "\n",
    "    if time_now - time_prev > 0 and 0.0000001 < time_now - time_prev < 0.58: # 0.578111 is highest diff i have seen\n",
    "        # in this case row_prev is x1 and row_now is x2\n",
    "        row1 = row_prev\n",
    "        row2 = row_now\n",
    "\n",
    "    elif time_next - time_now > 0 and 0.0000001 < time_next - time_now < 0.58:\n",
    "        # in this case row_now is x1 and row_next is x2\n",
    "        row1 = row_now\n",
    "        row2 = row_next\n",
    "\n",
    "    x1, y1 = preprocess_image_valid_from_path(row1['image_path'].values[0], row1['speed'].values[0])\n",
    "    x2, y2 = preprocess_image_valid_from_path(row2['image_path'].values[0], row2['speed'].values[0])\n",
    "    img_diff = x1 - x2\n",
    "    img_diff_reshaped = img_diff.reshape(1, img_diff.shape[0], img_diff.shape[1], img_diff.shape[2])\n",
    "    y = np.mean([y1, y2])\n",
    "    batch.append(img_diff)\n",
    "    labels.append(y)\n",
    "    \n",
    "print('done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "* Evaluate on subset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Evaluate model performance\n",
    "* Note we use mean y because that is what the model is estimating\n",
    "* Ground truth y would be y2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### MSE for 18 epochs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model = nvidia_model()\n",
    "model.load_weights('model-weights-F5.h5')\n",
    "batch = np.asarray(batch)\n",
    "labels = np.asarray(labels)\n",
    "model.evaluate(batch, labels, batch_size = 800)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### MSE for 30 epochs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model = nvidia_model()\n",
    "model.load_weights('model-weights-F4.h5')\n",
    "batch = np.asarray(batch)\n",
    "labels = np.asarray(labels)\n",
    "model.evaluate(batch, labels, batch_size = 800)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Hopefully the 30 epoch model isn't overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Overlay prediction onto images and save to new directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "mkdir ./data/predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Overlay prediction onto images and save to new directory `predict`\n",
    "* Note: This will use whatever `model` is in context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model = nvidia_model()\n",
    "model.load_weights('model-weights-F4.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "# given an input image\n",
    "\n",
    "data = pd.read_csv('./data/driving.csv')                    \n",
    "for idx in range(1, len(data.index) - 1):\n",
    "    row_now = data.iloc[[idx]].reset_index()\n",
    "    row_prev = data.iloc[[idx - 1]].reset_index()\n",
    "    row_next = data.iloc[[idx + 1]].reset_index()\n",
    "\n",
    "    # Find the 3 respective times to determine frame order (current -> next)\n",
    "\n",
    "    time_now = row_now['time'].values[0]\n",
    "    time_prev = row_prev['time'].values[0]\n",
    "    time_next = row_next['time'].values[0]\n",
    "\n",
    "    if time_now - time_prev > 0 and 0.0000001 < time_now - time_prev < 0.58: # 0.578111 is highest diff i have seen\n",
    "        # in this case row_prev is x1 and row_now is x2\n",
    "        row1 = row_prev\n",
    "        row2 = row_now\n",
    "\n",
    "    elif time_next - time_now > 0 and 0.0000001 < time_next - time_now < 0.58:\n",
    "        # in this case row_now is x1 and row_next is x2\n",
    "        row1 = row_now\n",
    "        row2 = row_next\n",
    "\n",
    "    x1, y1 = preprocess_image_valid_from_path(row1['image_path'].values[0], row1['speed'].values[0])\n",
    "    x2, y2 = preprocess_image_valid_from_path(row2['image_path'].values[0], row2['speed'].values[0])\n",
    "    img_diff = x1 - x2\n",
    "                                   \n",
    "    # reshape image difference to feed into model.predict\n",
    "    img_diff_reshaped = img_diff.reshape(1, img_diff.shape[0], img_diff.shape[1], img_diff.shape[2])\n",
    "        \n",
    "    # grab the mean speed y to check our model against\n",
    "    y = np.mean([y1, y2])\n",
    "                                   \n",
    "    # note: y2 is the actual speed of the frame x2 which we will use for accurate prediction, even though\n",
    "    # our model is based on x1 and x2\n",
    "                                   \n",
    "    # TODO: retrain model to evaluate y2 instead of mean(y1, y2) and check differences\n",
    "                                   \n",
    "    prediction = model.predict(img_diff_reshaped)\n",
    "    error = abs(prediction - y2)\n",
    "    truth = y2\n",
    "                                       \n",
    "    predict_path = os.path.join('./data/predict/', str(idx) + '.jpg')\n",
    "                                   \n",
    "    # overwrite the prediction of y2 onto image x2\n",
    "    # save overwritten image x2 to new directory ./data/predict\n",
    "\n",
    "                                   \n",
    "    # Make a copy \n",
    "    x2_copy = np.copy(x2)\n",
    "    \n",
    "    dst = opticalFlowOverlay(x1, x2)\n",
    "    \n",
    "    # now we have image 1 (x1) and image 2 (x2)\n",
    "    \n",
    "    \n",
    "    # to write new image via openCV\n",
    "    offset = 10\n",
    "    FONT_SIZE = 0.3\n",
    "    THICKNESS = 1\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    cv2.putText(dst,'pred: ' + str(prediction[0][0])[:5],(5,offset), font, FONT_SIZE,(0,0,0), THICKNESS,cv2.LINE_AA)\n",
    "    cv2.putText(dst,'truth: ' + str(y2)[:5],(5,offset * 2), font, FONT_SIZE,(0,20,255), THICKNESS,cv2.LINE_AA)\n",
    "    cv2.putText(dst, 'error: ' + str(error[0][0])[:5], (5, offset*3),font, FONT_SIZE, (255, 0, 0), THICKNESS, cv2.LINE_AA)\n",
    "    \n",
    "    # convert back to BGR for writing\n",
    "    dst = cv2.cvtColor(dst, cv2.COLOR_RGB2BGR)\n",
    "    cv2.imwrite(predict_path, dst)\n",
    "    \n",
    "print('done!')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Create video from sequence of images\n",
    "* This is from the 30 epoch model, the video in the README is from the 30 epoch model, which is on youtube [here](http://www.youtube.com/embed/WofBjhlaWqQ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from moviepy.editor import VideoFileClip\n",
    "from moviepy.editor import ImageSequenceClip\n",
    "import glob\n",
    "import os\n",
    "\n",
    "images = ['./data/predict/' + str(i+1) + '.jpg' for i in range(0, 4457)]\n",
    "clip = ImageSequenceClip(images, fps=13)\n",
    "clip.write_videofile(\"movie_small_optical_dense.mp4\", fps = 13)\n",
    "print('done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# rm -rf ./data/predict/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format('movie.mp4'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### TODO: perform opticalFlowOverlay before conversion from (480, 640, 3) -> (66, 200, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Reflection\n",
    "* Around 3 min into the video when we go onto the freeway the ground truth value is ~0 and the predicted value is ~0. I am quite unsure why this is.\n",
    "* When we go onto the freeway again ~4min in it looks like it's doing a pretty good job of predicting the speed, except for the part where we drive into the garage, it is predicting ~27 mph but that can't be true. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Other Approaches\n",
    "* I notices this article: (http://nicolovaligi.com/car-speed-estimation-windshield-camera.html#Giachetti1999) and this code: (https://gist.github.com/nicolov/d010233ea8d35887c6ab47cca97d396f) that uses Optical Flow to for Car Speed estimation using a single windshield camera. I copied the code, modified some fields so it worked with my dataset and ran it to see what happens.\n",
    "* An interesting thing to note is that in this code he is using ground truth data to calibrate the `hf` factor. Still, once the car goes on the freeway and deals with speeds > 30mph it fails completely. \n",
    "I ran the code with my dataset, which you can see in <strong>OpticalFlow.ipynb </strong>, and here is the result I got.\n",
    "* When I ran this code, I cropped out a ton of the image, meaning I lost a bunch of data. There are points when driving that the background and scenery can help define changes in velocity. Such as the difference in a trees position from one frame to the next, for this reason I went with the CNN approach.\n",
    "* Next steps: My next step is to compute the optical flow for each (current_image, next_frame) and feed that into my network as well. This way I can have the best of both worlds. Stay tuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "result = mpimg.imread('./data/optical_flow_result.png')\n",
    "plt.imshow(result)\n",
    "plt.axis('off')\n",
    "plt.title('Optical Flow Analysis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### <font color = 'green'>Optical Flow</font> vs <font color = 'blue'>CNN</font> Analysis\n",
    "* <font color = 'green'>3/4 in to the video, when we are absolutely on the freeway optical flow analysis tanks </font>\n",
    "* <font color = 'blue'>In the CNN approach, we did pretty well 3/4ths into the video, I would say that the CNN's estimation was better than a pure optical flow approach, (assuming I did not overfit the dataset)</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Future considerations\n",
    "* If I had more time I would finish my DeepVO implementation [DeepVO](https://arxiv.org/pdf/1611.06069.pdf), which I started to write but did not finish. You can see DeepVO in <strong>DeepVO.ipynb</strong>\n",
    "* I would also try to implement [DeepFlow](http://www.cv-foundation.org/openaccess/content_iccv_2013/papers/Weinzaepfel_DeepFlow_Large_Displacement_2013_ICCV_paper.pdf) which claims to have great performance. \n",
    "* I would also consider trying [FlowNet](https://arxiv.org/pdf/1504.06852.pdf) and I would use this as a [guide] (https://github.com/ClementPinard/FlowNetPytorch)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
